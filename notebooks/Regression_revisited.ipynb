{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.mlab import csv2rec\n",
    "import numpy as np\n",
    "from numpy import mean, sqrt, std, fabs\n",
    "\n",
    "# stats60 specific\n",
    "\n",
    "figsize = (8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple linear regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first type of model, which we will spend a lot of time on, is the *simple linear regresssion model*. One simple way to think of it\n",
    "is via scatter plots. Below are [heights](http://www.stat.cmu.edu/~roeder/stat707/=data/=data/data/Rlibraries/alr3/html/heights.html) of mothers and daughters collected \n",
    "by Karl Pearson in the late 19th century. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from code.week2 import pearson_lee\n",
    "heights = pearson_lee()\n",
    "M = heights.M\n",
    "D = heights.D\n",
    "%R -i M,D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "heights_fig = plt.figure(figsize=figsize)\n",
    "axes = heights_fig.gca()\n",
    "axes.scatter(M, D, c='red')\n",
    "axes.set_xlabel(\"Mother's height (inches)\", size=20)\n",
    "axes.set_ylabel(\"Daughter's height (inches)\", size=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The regression model puts a line through this scatter plot in an *optimal* fashion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%R -o slope,intercept\n",
    "parameters = lm(D~M)$coef\n",
    "print(parameters)\n",
    "intercept = parameters[1]\n",
    "slope = parameters[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "axes.plot([M.min(), M.max()], [intercept + slope * M.min(), intercept + slope * M.max()],\n",
    "          linewidth=3)\n",
    "heights_fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simple linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " *  *Simple linear* regression is the case when there is only one predictor:\n",
    "   $$\n",
    "   f({\\tt Mother}) = \\beta_0 + \\beta_1  \\cdot {\\tt Mother}.$$\n",
    "\n",
    "* Let $Y_i$ be the height of the $i$-th daughter in the sample, $X_i$ be the height of the $i$-th mother.\n",
    "\n",
    "* Model:\n",
    "   $$\n",
    "   Y_i = \\underbrace{\\beta_0 + \\beta_1 X_i}_{\\text{regression equation}} + \\underbrace{\\varepsilon_i}_{\\text{error}}$$\n",
    "   where $\\varepsilon_i \\sim N(0, \\sigma^2)$ are independent.\n",
    "\n",
    "* This specifies a *distribution* for the $Y$'s given the $X$'s, i.e.\n",
    "   it is a *statistical model*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: wages vs. experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "In this example, we'll look at the output of *lm* for the wage\n",
    "data and verify that some of the equations we present for the \n",
    "least squares solutions agree with the output.\n",
    "The data was compiled from a study in econometrics [Learning about Heterogeneity in Returns to Schooling]( http://www.econ.queensu.ca/jae/2004-v19.7/koop-tobias/readme.kt.txt).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "url = 'http://stats191.stanford.edu/data/wage.csv'\n",
    "wages = read.table(url, sep=',', header=T)\n",
    "print(head(wages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's fit the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "wages.lm = lm(logwage ~ education, data=wages)\n",
    "attach(wages)\n",
    "print(wages.lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As in the mother-daughter data, we might want to plot the data and add the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%R -h 800 -w 800\n",
    "plot(education, logwage, pch=23, bg='red', cex=2)\n",
    "abline(wages.lm, lwd=4, col='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Least squares estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are explicit formulae for the least squares estimators, i.e. the minimizers of the error sum of squares.\n",
    "\n",
    "For the slope, $\\hat{\\beta}_1$, it can be shown that \n",
    "$$\n",
    "   \\widehat{\\beta}_1 = \\frac{\\sum_{i=1}^n(X_i - \\overline{X})(Y_i - \\overline{Y}\n",
    ")}{\\sum_{i=1}^n (X_i-\\overline{X})^2} = \\frac{\\widehat{Cov}(X,Y)}{\\widehat{Var}(\n",
    "X)}.$$\n",
    "\n",
    "Knowing the slope estimate, the intercept estimate can be found easily:\n",
    "$$ \\widehat{\\beta}_0 = \\overline{Y} - \\widehat{\\beta}_1 \\cdot \\overline{\n",
    "X}.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimate of $\\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There is one final quantity needed to estimate all of our parameters in our (statistical) model for the scatterplot. This is $\\sigma^2$,\n",
    "the variance of the random variation within each slice (the regression model assumes this variance is constant within each slice...).\n",
    "\n",
    "The estimate most commonly used is\n",
    "$$\n",
    "\\hat{\\sigma}^2 = \\frac{1}{n-2} \\sum_{i=1}^n (Y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 X_i)^2 = \\frac{SSE}{n-2} = MSE\n",
    "$$\n",
    "\n",
    "Above, note the practice of replacing the quantity $SSE(\\hat{\\beta}_0,\\hat{\\beta}_1)$, i.e. the minimum of this function, with just $SSE$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The term *MSE* above refers to mean squared error: a sum of squares divided by what we call its *degrees of freedom*. The degrees of freedom\n",
    "of *SSE*, the *error sum of squares* is therefore $n-2$. Remember this $n-2$ corresponded to $\\perp$ in the picture above...\n",
    "\n",
    "Using some statistical calculations that we will not dwell on, if our simple linear regression model is correct, then we can see that\n",
    "$$\n",
    "\\frac{\\hat{\\sigma}^2}{\\sigma^2} \\sim \\frac{\\chi^2_{n-2}}{n-2}\n",
    "$$\n",
    "where the right hand side denotes a *chi-squared* distribution with $n-2$ degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Wages example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "sigma.hat = sqrt(sum(resid(wages.lm)^2) / wages.lm$df.resid)\n",
    "sigma.hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The summary from *R* also contains this estimate of $\\sigma$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "summary(wages.lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inference for the simple linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Recall our model $$\n",
    "   Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i,$$\n",
    "   errors $\\varepsilon_i$ are independent $N(0, \\sigma^2)$.\n",
    "   \n",
    "* In our heights example, we might want to now if there\n",
    "   really is a linear association between ${\\tt Daughter}=Y$\n",
    "   and ${\\tt Mother}=X$. This can be answered with a *hypothesis test* of the null hypothesis $H_0:\\beta_1=0$.\n",
    "   This assumes the model above is correct, but that $\\beta_1=0$.\n",
    "   \n",
    "* Alternatively, we might want to have a range of values that we can be fairly certain $\\beta_1$ lies within.\n",
    "This is a *confidence interval* for $\\beta_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Setup for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* It turns out that\n",
    "$$\n",
    "   \\widehat{\\beta}_1 \\sim N\\left(\\beta_1, \\frac{\\sigma^2}{\\sum_{i=1}^n(X_i-\\overline{X})^2}\\right).$$\n",
    "\n",
    "* Therefore, $$\\frac{\\widehat{\\beta}_1 - \\beta_1}{\\sigma \\sqrt{\\frac{1}{\\sum_{i=1}^n(X_i-\\overline{X})^2}}} \\sim N(\\\n",
    "0,1).$$\n",
    "\n",
    "* The other quantity we need is the *standard error* or SE of $\\hat{\\beta}_1$. This is\n",
    "obtained from estimating the variance of $\\widehat{\\beta}_1$, which, in this case means simply\n",
    "plugging in our estimate of $\\sigma$, yielding\n",
    "$$\n",
    "   SE(\\widehat{\\beta}_1) = \\widehat{\\sigma} \\sqrt{\\frac{1}{\\sum_{i=1}^n(X_i-\\overline{X})^2}} \\qquad \n",
    "   \\text{independent of $\\widehat{\\beta}_1$}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Testing $H_0:\\beta_1=\\beta_1^0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Suppose we want to test that $\\beta_1$ is some pre-specified\n",
    "   value, $\\beta_1^0$ (this is often 0: i.e. is there a linear association)\n",
    "\n",
    "* Under $H_0:\\beta_1=\\beta_1^0$\n",
    "   $$\\frac{\\widehat{\\beta}_1 - \\beta^0_1}{\\widehat{\\sigma} \\sqrt{\\frac{1}{\\sum_{i=1}^n(X_i-\\overline{X})^2}}}\n",
    "   = \\frac{\\widehat{\\beta}_1 - \\beta^0_1}{ \\frac{\\widehat{\\sigma}}{\\sigma}\\cdot \\sigma \\sqrt{\\frac{1}{\n",
    "\\sum_{i=1}^n(X_i-\\overline{X})^2}}} \\sim t_{n-2}.$$\n",
    "\n",
    "\n",
    "* Reject $H_0:\\beta_1=\\beta_1^0$ if $|T| > t_{n-2, 1-\\alpha/2}$.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Wage example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's perform this test for the wage data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "beta.1.hat = wages.lm$coef[\"education\"]\n",
    "SE.beta.1.hat = (sigma.hat * sqrt(1 / sum((education - mean(education))^2)))\n",
    "Tstat = beta.1.hat / SE.beta.1.hat\n",
    "data.frame(beta.1.hat, SE.beta.1.hat, Tstat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at the output of the `lm` function again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "summary(wages.lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We see that *R* performs this test in the second row of the `Coefficients` table. It is clear that\n",
    "wages are correlated with education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Confidence interval based on Student's $t$ distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*   Suppose we have a parameter estimate $\\widehat{\\theta} \\sim N(\\theta, {\\sigma}_{\\theta}^2)$, and standard error $SE(\\widehat{\\theta})$ such that\n",
    "   $$\n",
    "   \\frac{\\widehat{\\theta}-\\theta}{SE(\\widehat{\\theta})} \\sim t_{\\nu}.$$\n",
    "\n",
    "* We can find a $(1-\\alpha) \\cdot 100 \\%$ confidence interval by:\n",
    "   $$\n",
    "   \\widehat{\\theta} \\pm SE(\\widehat{\\theta}) \\cdot t_{\\nu, 1-\\alpha/2}.$$\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Confidence interval for regression parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Applying the above to the parameter $\\beta_1$ yields a confidence interval of the form\n",
    "$$\n",
    "   \\hat{\\beta}_1 \\pm SE(\\hat{\\beta}_1) \\cdot t_{n-2, 1-\\alpha/2}.$$\n",
    "   \n",
    "* We will need to compute $SE(\\hat{\\beta}_1)$. This can be computed using this formula\n",
    "   $$\n",
    "   SE(a_0\\hat{\\beta}_0 + a_1\\hat{\\beta}_1) = \\hat{\\sigma} \\sqrt{\\frac{a_0^2}{n} + \\frac{(a_0\\overline{X} - a_1)^2}{\\sum_{i=1}^n \\left(X_i-\\overline{X}\\right)^2}}.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We also need to find the quantity $t_{n-2,1-\\alpha/2}$. This is defined by\n",
    "$$\n",
    "\\mathbb{P}(T_{n-2} \\geq t_{n-2,1-\\alpha/2}) = \\alpha/2.\n",
    "$$\n",
    "In *R*, this is computed by the function `qt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "alpha = 0.05\n",
    "n = length(wages$education)\n",
    "qt(1-0.5*alpha,n-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Not surprisingly, this is close to that of the normal distribution, which is a Student's $t$ with $\\infty$ for degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "qnorm(1-0.5*alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "L = beta.1.hat - qt(0.95, wages.lm$df.resid) * SE.beta.1.hat\n",
    "U = beta.1.hat + qt(0.95, wages.lm$df.resid) * SE.beta.1.hat\n",
    "data.frame(L, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "confint(wages.lm)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
