{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmagic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "import matplotlib.mlab as ML\n",
      "H = ML.csv2rec('%s/pearson_lee.csv' % datadir)\n",
      "M = H['mother']\n",
      "D = H['daughter']\n",
      "pylab.scatter(M, D, c='red')\n",
      "xf, yf = pylab.poly_between([67.5,68.5], [50,50], [75, 75])\n",
      "g = (M < 68.5) * (M >= 67.5)\n",
      "pylab.fill(xf, yf, facecolor='blue', alpha=0.4, hatch='/', label='_nolegend_')\n",
      "pylab.gca().set_xlabel(\"Mother's height (inches)\")\n",
      "pylab.gca().set_ylabel(\"Daughter's height (inches)\")\n",
      "s = pylab.scatter([68],D[g].mean(), s=130, c='black', marker='^')\n",
      "s.set_label('Average at 68')\n",
      "Dbar = D.mean(); Dsd = np.sqrt(((D - Dbar)**2).mean())\n",
      "Mbar = M.mean(); Msd = np.sqrt(((M - Mbar)**2).mean())\n",
      "pylab.plot([Mbar-3.5*Msd,Mbar,Mbar+3.5*Msd],\n",
      "           [Dbar-3.5*Dsd,Dbar,Dbar+3.5*Dsd], 'b-', linewidth=3, label='SD line')\n",
      "pylab.legend(['SD line'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "The average in the 68in strip is below the SD line."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Regression line\n",
      "\n",
      "* Instead of the SD line we choose a line that minimizes the \"vertical distances\" from each point to the line.\n",
      "* The quality of a line is measured by the r.m.s. of these distances, called * residuals*\n",
      "  .\n",
      "* Each choice of slope / intercept yields a new set of residuals.\n",
      "* The regression line has the residuals with smallest r.m.s.\n",
      "* This is using the * least squares*\n",
      "   to choose the slope and intercept."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Intercept=4, Slope=0.3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "import matplotlib.mlab as ML\n",
      "D = ML.csv2rec('%s/sample_regression.csv' % datadir)\n",
      "X = D['x']\n",
      "Y = D['y']\n",
      "pylab.scatter(X,Y)\n",
      "\n",
      "a = 0.3*X + 4\n",
      "for i in range(X.shape[0]):\n",
      "    pylab.arrow(X[i], Y[i], 0, a[i] - Y[i], color='red')\n",
      "SSE = np.sum((a-Y)**2)\n",
      "pylab.plot([X.min(), X.max()],[0.3*X.min()+4,0.3*X.max()+4], 'r-', linewidth=3)\n",
      "pylab.title('Error(slope=0.3, intercept=4): %0.2f' % np.sqrt(SSE / X.shape[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Error is r.m.s. of ** lengths**\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Fit for SD line"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "import matplotlib.mlab as ML\n",
      "D = ML.csv2rec('%s/sample_regression.csv' % datadir)\n",
      "X = D['x']\n",
      "Y = D['y']\n",
      "pylab.scatter(X,Y)\n",
      "\n",
      "slope = Y.std() / X.std()\n",
      "intercept = Y.mean() - slope * X.mean()\n",
      "a = slope*X + intercept\n",
      "for i in range(X.shape[0]):\n",
      "    pylab.arrow(X[i], Y[i], 0, a[i] - Y[i], color='red')\n",
      "SSE = np.sum((a-Y)**2)\n",
      "pylab.plot([X.min(), X.max()],[slope*X.min()+intercept,slope*X.max()+intercept], 'r-', linewidth=3)\n",
      "pylab.title('Error(SD line): %0.2f' % np.sqrt(SSE / X.shape[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Regression line\n",
      "\n",
      "* The best fitting regression line passes through the point of averages and has slope $\\text{slope} = r(X,Y) \\times \\frac{SD(Y)}{SD(X)}.$\n",
      "* The intercept is $\\text{intercept} = \\bar{Y} - \\text{slope} \\times \\bar{X}.$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Fit for regression line"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "import matplotlib.mlab as ML\n",
      "D = ML.csv2rec('%s/sample_regression.csv' % datadir)\n",
      "X = D['x']\n",
      "Y = D['y']\n",
      "pylab.scatter(X,Y)\n",
      "\n",
      "slope = np.corrcoef([X,Y])[0,1] * Y.std() / X.std()\n",
      "intercept = Y.mean() - slope * X.mean()\n",
      "a = slope*X + intercept\n",
      "for i in range(X.shape[0]):\n",
      "    pylab.arrow(X[i], Y[i], 0, a[i] - Y[i], color='red')\n",
      "SSE = np.sum((a-Y)**2)\n",
      "pylab.plot([X.min(), X.max()],[slope*X.min()+intercept,slope*X.max()+intercept], 'r-', linewidth=3)\n",
      "pylab.title('Error(regression line): %0.2f' % np.sqrt(SSE / X.shape[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "import matplotlib.mlab as ML\n",
      "H = ML.csv2rec('%s/pearson_lee.csv' % datadir)\n",
      "M = H['mother']\n",
      "D = H['daughter']\n",
      "pylab.scatter(M, D, c='red')\n",
      "pylab.gca().set_xlabel(\"Mother's height (inches)\")\n",
      "pylab.gca().set_ylabel(\"Daughter's height (inches)\")\n",
      "Dbar = D.mean(); Dsd = np.sqrt(((D - Dbar)**2).mean())\n",
      "Mbar = M.mean(); Msd = np.sqrt(((M - Mbar)**2).mean())\n",
      "r = np.corrcoef([M, D])[0,1]\n",
      "pylab.plot([Mbar-3.5*Msd,Mbar,Mbar+3.5*Msd],\n",
      "           [Dbar-3.5*Dsd,Dbar,Dbar+3.5*Dsd], 'b-', linewidth=3, label='SD line')\n",
      "pylab.plot([Mbar-3.5*Msd,Mbar,Mbar+3.5*Msd],\n",
      "           [Dbar-r*3.5*Dsd,Dbar,Dbar+r*3.5*Dsd], '-', linewidth=3, label='regression', color='black')\n",
      "pylab.legend(['SD line', 'regression'])\n",
      "\n",
      "def error(a,b):\n",
      "    F = a*M+b\n",
      "    return np.sqrt(np.sum((D-F)**2))\n",
      "\n",
      "slope_SD = D.std() / M.std()\n",
      "intercept_SD = D.mean() - slope_SD * M.mean()\n",
      "\n",
      "slope_r = np.corrcoef([D,M])[0,1] * D.std() / M.std()\n",
      "intercept_r = D.mean() - slope_r * M.mean()\n",
      "\n",
      "pylab.title('Error(SD line)=%0.1f, Error(regression)=%0.1f' %\n",
      "            (error(slope_SD, intercept_SD),\n",
      "            error(slope_r, intercept_r)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "The mother/daughter data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "import matplotlib.mlab as ML\n",
      "H = ML.csv2rec('%s/pearson_lee.csv' % datadir)\n",
      "M = H['mother']\n",
      "D = H['daughter']\n",
      "pylab.scatter(M, D, c='red')\n",
      "pylab.gca().set_xlabel(\"Mother's height (inches)\")\n",
      "pylab.gca().set_ylabel(\"Daughter's height (inches)\")\n",
      "Dbar = D.mean(); Dsd = np.sqrt(((D - Dbar)**2).mean())\n",
      "Mbar = M.mean(); Msd = np.sqrt(((M - Mbar)**2).mean())\n",
      "r = np.corrcoef([M, D])[0,1]\n",
      "\n",
      "xf, yf = pylab.poly_between([67.5,68.5], [50,50], [75, 75])\n",
      "g = (M < 68.5) * (M >= 67.5)\n",
      "pylab.fill(xf, yf, facecolor='blue', alpha=0.4, hatch='/', label='_nolegend_')\n",
      "\n",
      "pylab.plot([Mbar-3.5*Msd,Mbar,Mbar+3.5*Msd],\n",
      "           [Dbar-3.5*Dsd,Dbar,Dbar+3.5*Dsd], 'b-', linewidth=3, label='SD line')\n",
      "pylab.plot([Mbar-3.5*Msd,Mbar,Mbar+3.5*Msd],\n",
      "           [Dbar-r*3.5*Dsd,Dbar,Dbar+r*3.5*Dsd], '-', linewidth=3, label='regression', color='black')\n",
      "pylab.legend(['SD line', 'regression'])\n",
      "\n",
      "def error(a,b):\n",
      "    F = a*M+b\n",
      "    return np.sqrt(np.sum((D-F)**2))\n",
      "\n",
      "slope_SD = D.std() / M.std()\n",
      "intercept_SD = D.mean() - slope_SD * M.mean()\n",
      "\n",
      "slope_r = np.corrcoef([D,M])[0,1] * D.std() / M.std()\n",
      "intercept_r = D.mean() - slope_r * M.mean()\n",
      "\n",
      "pylab.title('Error(SD line)=%0.1f, Error(regression)=%0.1f' %\n",
      "            (error(slope_SD, intercept_SD),\n",
      "            error(slope_r, intercept_r)))\n",
      "s = pylab.scatter([68],D[g].mean(), s=130, c='black', marker='^')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "The regression line is closer to the mean of 68 in group."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Working with regressions\n",
      " The following quantities are enough to do all regression problems\n",
      "* $\\text{average}(X), \\text{SD}(X)$\n",
      "* $\\text{average}(X), \\text{SD}(Y)$\n",
      "* $r(X,Y)$\n",
      "Example\n",
      " It is believed that the more alcohol there is in a person\u2019s blood stream, the slower is that person\u2019s reaction times. An experiment with 10 subjects yields\n",
      "* average amount of alcohol in blood $0.14\\%$ with SD $0.04\\%$\n",
      "* average reaction time 0.42 seconds, SD 0.1 seconds\n",
      "* correlation coefficient 0.8"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Question a)\n",
      "\n",
      "Q * Predict the reaction time of a person with an amount of alcohol of 0.22%.\n",
      "A1 * One way is to first compute the slope, intercept $\\begin{aligned}\n",
      "     \\text{slope} &= \\frac{0.8 \\times 0.1}{0.04} = 2.0 \\frac{\\text{seconds}}{\\%}     \\\\\n",
      "     \\text{intercept} &= 0.42 - 2. \\times 0.14 = 0.14 \\, \\text{seconds}\n",
      "     \\end{aligned}$ So, the predicted time is $2 \\times 0.22 + 0.14 = 0.58 \\, \\text{seconds}$\n",
      "A2 * $0.42 + (0.22 - 0.14) \\times 2. = 0.58 \\, \\text{seconds}$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Question b)\n",
      "\n",
      "Q * Find the regression line for regressing reaction time on alcohol level.\n",
      "A * From part A1 on previous slide: the predicted reaction time as a function of alcohol level is $0.14 + 2. \\times \\text{alcohol level in \\%}$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Question c)\n",
      "\n",
      "Q * Predict the reaction time of a person whose alcohol level is at the 20th percentile. What percentile does that correspond to in reaction time?\n",
      "A * The 20th percentile of blood alcohol is (using normal approximation) $\\begin{aligned}\n",
      "     \\lefteqn{0.14 + 0.04 \\times \\text{20th percentile of normal}} \\\\\n",
      "     & \\qquad = 0.14 + 0.04 \\times (-0.84) \\\\\n",
      "     & \\qquad = 0.11\n",
      "     \\end{aligned}$ So, we predict a reaction time of $0.14 + 2 \\times 0.11 = 0.36$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Question c) continued\n",
      "\n",
      "This is $(0.36-0.42)/0.1=-0.6$ in standardized units, so it corresponds to roughly the 30th percentile (from A-104)\n",
      "Question d)\n",
      "\n",
      "Q * Predict the amount of alcohol a person has in her bloodstream if the reaction time is 0.37 seconds.\n",
      "A * Using the A2 form from part a), we predict $0.14 + 0.8 \\times \\frac{0.04}{0.1} (0.37-0.42) = 0.124 \\%$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Regression fallacy\n",
      "\n",
      "* Note that someone in the 20th percentile of alcohol level had predicted 30th percentile in reaction time.\n",
      "* This is a general phenomenon, Galton referred to it as \"regression to mediocrity.\"\n",
      "Test-retest version of regression fallacy\n",
      " In a test-retest situation, usually the bottom group on the first test will show some improvement, and the top group will fall back."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "import matplotlib.mlab as ML\n",
      "## library(alr3)\n",
      "## data(heights)\n",
      "## attach(heights)\n",
      "## lm(Dheight ~ Mheight)\n",
      "\n",
      "H = ML.csv2rec('%s/pearson_lee.csv' % datadir)\n",
      "M = H['mother']\n",
      "D = H['daughter']\n",
      "pylab.scatter(M, D, c='red')\n",
      "pylab.gca().set_xlabel(\"Mother's height (inches)\")\n",
      "pylab.gca().set_ylabel(\"Daughter's height (inches)\")\n",
      "Dbar = D.mean(); Dsd = np.sqrt(((D - Dbar)**2).mean())\n",
      "Mbar = M.mean(); Msd = np.sqrt(((M - Mbar)**2).mean())\n",
      "r = np.corrcoef([M, D])[0,1]\n",
      "\n",
      "xf, yf = pylab.poly_between([67.5,68.5], [50,50], [75, 75])\n",
      "g = (M < 68.5) * (M >= 67.5)\n",
      "\n",
      "pylab.plot([Mbar-3.5*Msd,Mbar,Mbar+3.5*Msd],\n",
      "           [Dbar-3.5*Dsd,Dbar,Dbar+3.5*Dsd], 'b-', linewidth=3, label='SD line')\n",
      "pylab.plot([Mbar-3.5*Msd,Mbar,Mbar+3.5*Msd],\n",
      "           [Dbar-r*3.5*Dsd,Dbar,Dbar+r*3.5*Dsd], '-', linewidth=3, label='D on M', color='black')\n",
      "pylab.plot([Mbar-r*3.5*Msd,Mbar,Mbar+r*3.5*Msd],\n",
      "           [Dbar-3.5*Dsd,Dbar,Dbar+3.5*Dsd], '-', linewidth=3, label='M on D', color='yellow')\n",
      "pylab.legend(['SD line', 'D on M', 'M on D'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "There are two regression lines"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Prediction and regression\n",
      "\n",
      "* While there are two regression lines, the right way to remember which to use is * what do you want to predict*\n",
      "  ?\n",
      "* The variable you want to predict goes on the vertical axis ($Y$-axis).\n",
      "* The variable you want to base your prediction on goes on the vertical axis ($X$-axis).\n",
      "* In many situations, it will be more natural to predict one variable instead of another."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Accuracy of prediction\n",
      "\n",
      "* In discussing experiments, we discussed the average of a set of measurements.\n",
      "* These can be used to predict a new measurement: our best guess is just the average of the previous meausrements."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "SD as a measure of accuracy\n",
      "\n",
      "* The SD of the set of measurements gives us some idea of how accurate our prediction is $\\text{SD(list) = r.m.s.(deviations from average)}$\n",
      "* If our prediction is the average, then $\\text{SD(list) = r.m.s.(deviations from predictions)}$\n",
      "* With regression, we have a new way to predict: using the regression line."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Accuracy of prediction in regression\n",
      "\n",
      "* In regression, we are using more information: the fact that tall mothers tend to give birth to taller daughters (but not quite as tall).\n",
      "* This should improve the accuracy of our prediction of the daughter\u2019s height (which uses the mother\u2019s height)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      " of regression\n",
      "\n",
      "* Our regression line was chosen to minimize the r.m.s. of the residuals of all ines $$\n",
      "* () &=\n",
      "  &=\n",
      "  \n",
      "* $$\n",
      "* This r.m.s. is always less than the SD of the dependent variable ($Y$) alone $$ () = (Y) $$\n",
      "* In mother/daughter example, this factor is 87%."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "SD is based on residuals"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "X = seq(0,20, length=21)\n",
      "Y = 0.5*X+1 + rnorm(21)\n",
      "\n",
      "Y.lm = lm(Y~X)\n",
      "\n",
      "p = predict(Y.lm)\n",
      "m = mean(Y)\n",
      "\n",
      "# SST: deviations of Y's around\n",
      "# the horizontal line for the mean\n",
      "\n",
      "plot(X, Y, pch=23, bg='red')\n",
      "abline(h=m, col='yellow', lwd=2)\n",
      "for (i in 1:21) {\n",
      "  points(X[i], m, pch=23, bg='yellow')\n",
      "  lines(c(X[i], X[i]), c(Y[i], m))\n",
      "}\n",
      "\n",
      "# show the regression line as well\n",
      "\n",
      "abline(Y.lm, col='green', lwd=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "So is r.m.s.(regression)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "# SSE: deviations of Y's around\n",
      "# the regression line\n",
      "\n",
      "plot(X, Y, pch=23, bg='red')\n",
      "abline(Y.lm, col='green', lwd=2)\n",
      "for (i in 1:21) {\n",
      "  points(X[i], p[i], pch=23, bg='green')\n",
      "  lines(c(X[i], X[i]), c(Y[i], p[i]))\n",
      "}\n",
      "\n",
      "m = mean(Y)\n",
      "abline(h=m, col='yellow', lwd=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      " of regression\n",
      "\n",
      "* If the data cloud is football shaped, then the r.m.s. gives an estimate of the spread in each vertical strip of the regression line.\n",
      "* This is * homoscedastic*\n",
      "   scatter.\n",
      "* If the data cloud has a different shape, this scatter is called * heteroscedastic*\n",
      "   and the regression r.m.s. is not useful within a vertical strip"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Homoscedastic scatter"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "n = 300\n",
      "X = np.random.standard_normal(n)\n",
      "X.sort()\n",
      "w = 3\n",
      "Y = 4.5 * X + 1 + np.random.standard_normal(n) * w\n",
      "\n",
      "xf, yf = pylab.poly_between([-1.25,-0.75], [-20,-20], [20, 20])\n",
      "pylab.fill(xf, yf, facecolor='blue', alpha=0.4, hatch='/', label='_nolegend_')\n",
      "\n",
      "xf, yf = pylab.poly_between([0.75,1.25], [-20,-20], [20, 20])\n",
      "pylab.fill(xf, yf, facecolor='blue', alpha=0.4, hatch='/', label='_nolegend_')\n",
      "\n",
      "pylab.gca().set_yticks([])\n",
      "pylab.gca().set_xticks([])\n",
      "pylab.scatter(X, Y, c='red')\n",
      "pylab.gca().set_ylim([-10,15])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Heteroscedastic scatter"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "n = 300\n",
      "X = np.random.standard_normal(n)\n",
      "X.sort()\n",
      "w = np.linspace(1,6,n)\n",
      "Y = 0.5 * X + 1 + np.random.standard_normal(n) * w\n",
      "\n",
      "xf, yf = pylab.poly_between([-1.25,-0.75], [-20,-20], [20, 20])\n",
      "pylab.fill(xf, yf, facecolor='blue', alpha=0.4, hatch='/', label='_nolegend_')\n",
      "\n",
      "xf, yf = pylab.poly_between([0.75,1.25], [-20,-20], [20, 20])\n",
      "pylab.fill(xf, yf, facecolor='blue', alpha=0.4, hatch='/', label='_nolegend_')\n",
      "\n",
      "pylab.gca().set_yticks([])\n",
      "pylab.gca().set_xticks([])\n",
      "pylab.scatter(X, Y, c='red')\n",
      "pylab.gca().set_ylim([-10,15])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Income vs. Education"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "import matplotlib.mlab as ML\n",
      "\n",
      "D = ML.csv2rec('%s/wage.csv' % datadir)\n",
      "X = D['education']\n",
      "Y = D['logwage']\n",
      "Z = np.exp(Y)\n",
      "\n",
      "\n",
      "pylab.scatter(X, Z, c='red')\n",
      "a = pylab.gca()\n",
      "a.set_ylabel('Income (1000$)')\n",
      "a.set_xlabel('Education (years)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "log(Income) vs. Education"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "import matplotlib.mlab as ML\n",
      "\n",
      "D = ML.csv2rec('%s/wage.csv' % datadir)\n",
      "X = D['education']\n",
      "Y = D['logwage']\n",
      "Z = np.exp(Y)\n",
      "\n",
      "\n",
      "pylab.scatter(X, Y, c='red')\n",
      "a = pylab.gca()\n",
      "a.set_ylabel('log(Income (1000$))')\n",
      "a.set_xlabel('Education (years)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Logarithms may improve heteroscedastic scatter"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Example: using regression r.m.s. in vertical strips\n",
      "\n",
      "* Given the following $\\begin{aligned}\n",
      "         \\text{average(mother)} &= 62.4\\\\\n",
      "         \\text{SD(mother)} &= 2.3 \\\\\n",
      "         \\text{average(daughter)} &= 63.8 \\\\\n",
      "         \\text{SD(daughter)} &= 2.6 \\\\\n",
      "         \\text{r(mother, daughter)} &= 0.49\n",
      "       \\end{aligned}$ Of mothers of height 66in, what percentage of their daughters will have height above 67in?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Answer\n",
      "\n",
      "* Slope of regression line is $\\text{slope} = 0.49 \\times \\frac{2.6}{2.3} = 0.54$\n",
      "* The average height of daughters of mothers of height 66in is $63.8 + 0.54 \\times (66 - 62.4) = 65.7$\n",
      "* The SD is taken to be r.m.s. of regression $0.87 \\times 2.6 = 2.3.$\n",
      "* 67 in corresponds to $(67-65.7)/2.3=0.6$ standardized units.\n",
      "* From A-104, the percentage is roughly 27%."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "import matplotlib.mlab as ML\n",
      "D = ML.csv2rec('%s/quadratic_example.csv' % datadir)\n",
      "X = D['x']\n",
      "Y = D['y']\n",
      "pylab.scatter(X,Y, c='r', s=40)\n",
      "m = Y.std() * np.corrcoef([X,Y])[0,1] / X.std()\n",
      "b = Y.mean() - X.mean() * m\n",
      "\n",
      "r = ((X*Y).mean() - X.mean() * Y.mean()) / (X.std() * Y.std())\n",
      "pylab.plot([X.mean()-3.5*X.std(),X.mean()+3.5*X.std()],\n",
      "           [Y.mean()-r*3.5*Y.std(),Y.mean()+r*3.5*Y.std()],\n",
      "           '-', linewidth=3, label='M on D', color='black')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Regression doesn\u2019t work well for nonlinear patterns"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "import matplotlib.mlab as ML\n",
      "D = ML.csv2rec('%s/quadratic_example.csv' % datadir)\n",
      "X = D['x']\n",
      "Y = D['y']\n",
      "m = Y.std() * np.corrcoef([X,Y])[0,1] / X.std()\n",
      "b = Y.mean() - X.mean() * m\n",
      "\n",
      "p = m * X + b\n",
      "resid = Y - p\n",
      "pylab.scatter(X, resid, c='r', s=40)\n",
      "pylab.gca().set_ylabel('Residuals')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Plotting the residuals can identify nonlinear patterns"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "import matplotlib.mlab as ML\n",
      "D = ML.csv2rec('%s/heteroscedastic_example.csv' % datadir)\n",
      "X = D['x']\n",
      "Y = D['y']\n",
      "\n",
      "pylab.scatter(X, Y, s=40, c='red')\n",
      "pylab.gca().set_ylim([-10,15])\n",
      "m = Y.std() * np.corrcoef([X,Y])[0,1] / X.std()\n",
      "b = Y.mean() - X.mean() * m\n",
      "\n",
      "r = ((X*Y).mean() - X.mean() * Y.mean()) / (X.std() * Y.std())\n",
      "pylab.plot([X.mean()-3.5*X.std(),X.mean()+3.5*X.std()],\n",
      "           [Y.mean()-r*3.5*Y.std(),Y.mean()+r*3.5*Y.std()],\n",
      "           '-', linewidth=3, label='M on D', color='black')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import rc\n",
      "import pylab, numpy as np, sys\n",
      "np.random.seed(0);import random; random.seed(0)\n",
      "import matplotlib.mlab as ML\n",
      "D = ML.csv2rec('%s/heteroscedastic_example.csv' % datadir)\n",
      "X = D['x']\n",
      "Y = D['y']\n",
      "\n",
      "m = Y.std() * np.corrcoef([X,Y])[0,1] / X.std()\n",
      "b = Y.mean() - X.mean() * m\n",
      "\n",
      "p = m * X + b\n",
      "resid = Y - p\n",
      "pylab.scatter(X, resid, c='r', s=40)\n",
      "pylab.gca().set_ylabel('Residuals')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Can also help identify heteroscedasticity"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}