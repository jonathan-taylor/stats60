   \documentclass[handout]{beamer}



   \mode<presentation>
   {
     \usetheme{PaloAlto}
   \setbeamertemplate{footline}[page number]

     \setbeamercolor{sidebar}{bg=white, fg=black}
     \setbeamercolor{frametitle}{bg=white, fg=black}
     % or ...
     \setbeamercolor{logo}{bg=white}
     \setbeamercolor{block body}{parent=normal text,bg=white}
     \setbeamercolor{author in sidebar}{fg=black}
     \setbeamercolor{title in sidebar}{fg=black}


     \setbeamercolor*{block title}{use=structure,fg=structure.fg,bg=structure.fg!20!bg}
     \setbeamercolor*{block title alerted}{use=alerted text,fg=alerted text.fg,bg=alerted text.fg!20!bg}
     \setbeamercolor*{block title example}{use=example text,fg=example text.fg,bg=example text.fg!20!bg}


     \setbeamercolor{block body}{parent=normal text,use=block title,bg=block title.bg!50!bg}
     \setbeamercolor{block body alerted}{parent=normal text,use=block title alerted,bg=block title alerted.bg!50!bg}
     \setbeamercolor{block body example}{parent=normal text,use=block title example,bg=block title example.bg!50!bg}

     % or ...

     \setbeamercovered{transparent}
     % or whatever (possibly just delete it)
     \logo{\resizebox{!}{1.5cm}{\href{\basename{R}}{\includegraphics{image}}}}
   }

   \mode<handout>
   {
     \usetheme{PaloAlto}
     \usecolortheme{default}
     \setbeamercolor{sidebar}{bg=white, fg=black}
     \setbeamercolor{frametitle}{bg=white, fg=black}
     % or ...
     \setbeamercolor{logo}{bg=white}
     \setbeamercolor{block body}{parent=normal text,bg=white}
     \setbeamercolor{author in sidebar}{fg=black}
     \setbeamercolor{title in sidebar}{fg=black}
     \setbeamercovered{transparent}
     % or whatever (possibly just delete it)
     \logo{}
   }

   \usepackage{epsdice}
   \usepackage[latin1]{inputenc}
   \usepackage{graphics}
   \usepackage{amsmath,eepic,epic}

   \newcommand{\figslide}[3]{
   \begin{frame}
   \frametitle{#1}
     \begin{center}
     \resizebox{!}{2.7in}{\includegraphics{#2}}    
     \end{center}
   {#3}
   \end{frame}
   }

   \newcommand{\fighslide}[4]{
   \begin{frame}
   \frametitle{#1}
     \begin{center}
     \resizebox{!}{#4}{\includegraphics{#2}}    
     \end{center}
   {#3}
   \end{frame}
   }

   \newcommand{\figwref}[1]{
   \href{#1}{\tiny \tt #1}}

   \newcommand{\B}[1]{\beta_{#1}}
   \newcommand{\Bh}[1]{\widehat{\beta}_{#1}}
   \newcommand{\V}{\text{Var}}
   \newcommand{\Cov}{\text{Cov}}
   \newcommand{\Vh}{\widehat{\V}}
   \newcommand{\s}{\sigma}
   \newcommand{\sh}{\widehat{\sigma}}

   \newcommand{\argmax}[1]{\mathop{\text{argmax}}_{#1}}
   \newcommand{\argmin}[1]{\mathop{\text{argmin}}_{#1}}
   \newcommand{\Ee}{\mathbb{E}}
   \newcommand{\Pp}{\mathbb{P}}
   \newcommand{\real}{\mathbb{R}}
   \newcommand{\Ybar}{\overline{Y}}
   \newcommand{\Yh}{\widehat{Y}}
   \newcommand{\Xbar}{\overline{X}}
   \newcommand{\Tr}{\text{Tr}}


   \newcommand{\model}{{\cal M}}

   \newcommand{\figvskip}{-0.7in}
   \newcommand{\fighskip}{-0.3in}
   \newcommand{\figheight}{3.5in}

   \newcommand{\Rcode}[1]{{\bf \tt #1 }}
   \newcommand{\Rtcode}[1]{{\tiny \bf \tt #1 }}
   \newcommand{\Rscode}[1]{{\small \bf \tt #1 }}

   \newcommand{\RR}{{\tt R} \;}
   \newcommand{\basename}[1]{http://stats60.stanford.edu/#1}
   \newcommand{\dataname}[1]{\basename{data/#1}}
   \newcommand{\Rname}[1]{\basename{R/#1}}

   \newcommand{\mycolor}[1]{{\color{blue} #1}}
   \newcommand{\basehref}[2]{\href{\basename{#1}}{\mycolor{#2}}}
   \newcommand{\Rhref}[2]{\href{\basename{R/#1}}{\mycolor{#2}}}
   \newcommand{\datahref}[2]{\href{\dataname{#1}}{\mycolor{#2}}}
   \newcommand{\X}{\pmb{X}}
   \newcommand{\Y}{\pmb{Y}}
   \newcommand{\be}{\pmb{varepsilon}}
   \newcommand{\logit}{\text{logit}}


   \title{Statistics 60: Introduction to Statistical Methods}
   \subtitle{Chapter 28: The $\chi^2$ (chi-squared) test.} 
   \author{}% {Jonathan Taylor \\
   %Department of Statistics \\
   %Stanford University
   %}


   \begin{document}

   \begin{frame}
   \titlepage
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Goodness of fit}

   \begin{block}
   {Is the game fair?}
   \begin{itemize}
   \item In our quiz, we had a question about the number of pairs
   when two dice were rolled.

   \item In an earlier example, we considered the question about
   whether a roulette wheel was rigged based on the results
   from betting in {\color{red} RED}.

   \item In both of these cases, we came up with a test of ``rigged'' or
   ``not rigged'' based on one ``feature'' of the experiments.

   \item But, we could have looked at more than just these features, we could
   have looked at all of the outcomes \dots
   \item These are called ``goodness of fit'' tests.

   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Goodness of fit tests}

   \begin{block}
   {A simpler example}
   \begin{itemize}
   \item Suppose a die is rolled 60 times. These are the outcomes:

     \begin{center}
     \begin{tabular}{c|c}
       Value & Observed Count \\ \hline
       1 & 4   \\
       2 & 6 \\
       3 & 17 \\
       4 & 16 \\
       5 & 8 \\
       6 & 9 \\  \hline
       Total & 60 \\
     \end{tabular}
     \end{center}

   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Goodness of fit tests}

   \begin{block}
   {A simpler example}
   \begin{itemize}
   \item If the die were fair, we could add another column (OK, two columns).

     \begin{tabular}{c|c|c|p{1in}}
       {\small Value} & {\small Observed Count} & {\small Expected Count} & {\small Observed - Expected} \\ \hline
       1 & 4 & 10 & -6  \\
       2 & 6 & 10 & -4 \\
       3 & 17 & 10 & 7 \\
       4 & 16 & 10 & 6 \\
       5 & 8 & 10 & -2 \\
       6 & 9 & 10 & -1 \\ \hline
       Total & 60 & 60 & 0 \\
     \end{tabular}

     \item It seems there are too many 3's, and too few 1's...

   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Goodness of fit tests}

   \begin{block}
   {$\chi^2$ statistic}
   \begin{itemize}
   \item To get an overall tests, we combine the rows into {\em Pearson's $\chi^2$}
     $$
     \begin{aligned}
     {\color{orange} \chi^2} &= {\color{orange} \text{sum} \left(\frac{\text{(Observed - Expected)$^2$}}{\text{Expected}}\right)} = {\color{orange} \sum_{i=1}^6 \frac{(O_i - E_i)^2}{E_i}}
     \end{aligned}
     $$

     \item In the die example,
       $$
       \begin{aligned}
       {\color{orange} \chi^2} &= {\color{orange} \frac{(-6)^2}{10} + \frac{(-4)^2}{10} + \frac{7^2}{10} + \frac{6^2}{10} + \frac{(-2)^2}{10} + \frac{(-1)^2}{10}} \\
       &= {\color{orange} \frac{142}{10}} \\
       &= {\color{orange} 14.2}
       \end{aligned}
       $$

   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % sys.path.append('/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf')
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % datadir ='/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf/data'
   % import pylab, numpy as np
   % import scipy.stats
   % x = np.linspace(0,20,101)
   % y = scipy.stats.chi2.pdf(x, 5)
   % x2 = np.linspace(14.2,20,101)
   % y2 = scipy.stats.chi2.pdf(x2, 5)
   % pylab.plot(x,y*100, linewidth=2)
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='red', hatch='\\', alpha=0.5)
   % pylab.gca().set_xlabel('standardized units')
   % pylab.gca().set_ylabel('% per standardized unit')
   % 


   \begin{frame}
   \frametitle{What are the chances?}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/2ca98aef04.pdf}}    
   \end{center}
   The $\chi^2_5$ probability histogram, the area is 1.4\%
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{$\chi^2$ tables}

   \begin{block}
   {What was that last histogram?}
   \begin{itemize}
     \item It is a new kind of probability histogram, called a $\chi^2$ probability histogram or curve.
   \item The $\chi^2$ probability histogram or curve also has
    {\em degrees of freedom} associated to it.
   \item To figure out the degrees of freedom,
     we need a box.

   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{$\chi^2$ curves}

   \begin{block}
   {Degrees of freedom}

   \begin{itemize}
   \item Our box is
     \begin{quote}
       \fbox{\epsdice{1} \  \epsdice{2} \  \epsdice{3} \  \epsdice{4} \  \epsdice{5} \  \epsdice{6}}
     \end{quote}
   \item Our goal is to see if our  fit the box. Our data is supposed to be
   60 draws with replacement from our box.

   \item There are 6 different objects in the box and we have an observation
   for each object. Maybe the degrees of
   freedom is 6?

   \item Not quite, it is 6-1=5. Why the -1? Because when we roll
   60 times, the observed counts must sum to 60 -- there are only 5 free
   variables.
   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{$\chi^2$ curves}

   \begin{block}
   {The $\chi^2$ curve}

   \begin{itemize}
   \item Even if the die is fair, the $\chi^2$ statistic
   will have some variability in it.

   \item The $\chi^2_5$ probability histogram describes this variability
   under ${\color{blue} H_0: \text{the die is fair}}$.

   \item The 1.4\% is the {\color{orange} $P$-value}, or the observed significance level.

   \item It is the probability we would observe a $\chi^2$ statistic as large as our observed {\color{orange} $\chi^2$} if ${\color{blue} H_0}$ is true.


   \item {\bf \color{red} It is not the probability $H_0$ is true.}

   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % sys.path.append('/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf')
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % datadir ='/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf/data'
   % import pylab, numpy as np
   % import scipy.stats
   % x = np.linspace(0,30,201)
   % y = scipy.stats.chi2.pdf(x, 5)
   % y2 = scipy.stats.chi2.pdf(x, 10)
   % pylab.plot(x,y*100, linewidth=2)
   % pylab.plot(x,y2*100, linewidth=2)
   % pylab.gca().set_xlabel('standardized units')
   % pylab.gca().set_ylabel('% per standardized unit')
   % 


   \begin{frame}
   \frametitle{$\chi^2$ curves}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/f43fd0bf33.pdf}}    
   \end{center}
   The $\chi^2_5$, $\chi^2_{10}$ probability histograms.
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % sys.path.append('/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf')
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % datadir ='/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf/data'
   % import pylab, numpy as np
   % import scipy.stats
   % df = 5
   % x = np.linspace(0,20,101)
   % y = scipy.stats.chi2.pdf(x, df)
   % x2 = np.linspace(scipy.stats.chi2.isf(0.05, df),20,101)
   % y2 = scipy.stats.chi2.pdf(x2, df)
   % pylab.plot(x,y*100, linewidth=2)
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='red', hatch='\\', alpha=0.5)
   % pylab.gca().set_xlabel('standardized units')
   % pylab.gca().set_ylabel('% per standardized unit')
   % pylab.title('Reject $H_0$ for $\chi^2_{%d}$ greater than %0.2f' % (df, scipy.stats.chi2.isf(0.05, df)))
   % 


   \begin{frame}
   \frametitle{$\chi^2$ curves}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/61d1407733.pdf}}    
   \end{center}
   The 5\% rejection rule for $\chi^2_5$
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % sys.path.append('/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf')
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % datadir ='/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf/data'
   % import pylab, numpy as np
   % import scipy.stats
   % df = 10
   % x = np.linspace(0,30,101)
   % y = scipy.stats.chi2.pdf(x, df)
   % x2 = np.linspace(scipy.stats.chi2.isf(0.05, df),30,101)
   % y2 = scipy.stats.chi2.pdf(x2, df)
   % pylab.plot(x,y*100, linewidth=2)
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='red', hatch='\\', alpha=0.5)
   % pylab.gca().set_xlabel('standardized units')
   % pylab.gca().set_ylabel('% per standardized unit')
   % pylab.title('Reject $H_0$ for $\chi^2_{%d}$ greater than %0.2f' % (df, scipy.stats.chi2.isf(0.05, df)))
   % 


   \begin{frame}
   \frametitle{$\chi^2$ curves}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/0dd5cfed50.pdf}}    
   \end{center}
   The 5\% rejection rule for $\chi^2_{10}$
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{$\chi^2$ curves}

   \begin{block}
   {Using the $\chi^2$ test}

   \begin{itemize}
   \item A general rule of thumb: every expected value should be 5 or more
   for the $\chi^2$ curve to approximate the probability
   histogram of the ${\color{orange} \chi^2}$ statistic.

   \item Would not apply to 100 draws from
     $$
       \fbox{ \fbox{1} \ \fbox{2} \  \fbox{3} \ \ 96 \fbox{4}'s}
     $$


   \end{itemize}
   \end{block}

   \begin{block}
     {Difference between $\chi^2$ test and $z$ test}
     \begin{itemize}
     \item The $z$ test is a statement about the average of the box.
     \item The $\chi^2$ is a test whether the  observed data follow the
     box model.
     \item If there are only two values in the box, then the
     $\chi^2$ test is identical to the (two-sided) $z$ test.
     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{$\chi^2$ curves}

   \begin{block}
   {Example}

   \begin{itemize}
   \item Suppose the box is \fbox{20 \fbox{{\color{red} A}}'s \ \ 30 \fbox{{\color{green} B}}'s}.
   \item In 100 draws with replacement, we observe 46 \fbox{{\color{red} A}}'s
   (and 54 \fbox{{\color{green} B}}'s).
   \item The $\chi^2$ test statistic is
     $$
     {\color{orange} \chi^2} = \frac{(46-40)^2}{40} + \frac{(54-60)^2}{60} = 1.5
     $$
   \item The $z$ statistic for the proportion of \fbox{{\color{red} A}}'s is
   $$
   {\color{orange} z} = \frac{0.46-0.40}{\sqrt{0.4 \times 0.6} / \sqrt{100}} = 1.224
   $$
   \item And, ${\color{orange} z}^2 = (1.224)^2 = 1.5$. This is not a coincidence \dots

   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % sys.path.append('/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf')
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % datadir ='/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf/data'
   % import pylab, numpy as np
   % import scipy.stats
   % df = 1
   % x = np.linspace(0,30,401)
   % y = scipy.stats.chi2.pdf(x, df)
   % x2 = np.linspace(scipy.stats.chi2.isf(0.05, df),30,401)
   % y2 = scipy.stats.chi2.pdf(x2, df)
   % pylab.plot(x,y*100, linewidth=2)
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='red', hatch='\\', alpha=0.5)
   % pylab.gca().set_xlabel('standardized units')
   % pylab.gca().set_ylabel('% per standardized unit')
   % pylab.gca().set_xlim([0,7])
   % pylab.title('Reject $H_0$ for $\chi^2_{%d}$ greater than %0.2f' % (df, scipy.stats.chi2.isf(0.05, df)))
   % 


   \begin{frame}
   \frametitle{$\chi^2$ curves}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/8581678eaa.pdf}}    
   \end{center}
   The 5\% rejection rule for $\chi^2_{1}$
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % sys.path.append('/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf')
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % datadir ='/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf/data'
   % import scipy.stats
   % import pylab, numpy as np
   % x = np.linspace(-4,4,101)
   % y = np.exp(-x**2/2) / np.sqrt(2*np.pi)
   % 
   % q = scipy.stats.norm.isf(0.025)
   % x2 = np.linspace(q,4,101)
   % y2 = np.exp(-x2**2/2) / np.sqrt(2*np.pi)
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='red', hatch='\\', alpha=0.5)
   % 
   % 
   % x2 = np.linspace(-4,-q,101)
   % y2 = np.exp(-x2**2/2) / np.sqrt(2*np.pi)
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='red', hatch='\\', alpha=0.5)
   % 
   % pylab.plot(x,y*100, linewidth=2)
   % pylab.gca().set_xlabel('standardized units')
   % pylab.gca().set_ylabel('% per standardized unit')
   % pylab.title('Reject $H_0$ for $|z|$ greater than %0.2f' % q)
   % 


   \begin{frame}
   \frametitle{$z$ test}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/7125fc11f1.pdf}}    
   \end{center}
   {\color{blue} Two-sided 5\% rejection rule}, (Note: $1.96^2 = 3.84$)
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{$\chi^2$ tests}

   \begin{block}
     {Structure of a $\chi^2$ test}
     \begin{description}
     \item[Basic Data] The number of draws, $N$ and the resulting draws.

     \begin{tabular}{c|c}
       Value & Observed Count \\ \hline
       1 & 4   \\
       2 & 6 \\
       3 & 17 \\
       4 & 16 \\
       5 & 8 \\
       6 & 9 \\  \hline
       Total & 60 (=$N$) \\
     \end{tabular}

     \item[Box] In this example: \fbox{\epsdice{1} \  \epsdice{2} \  \epsdice{3} \  \epsdice{4} \  \epsdice{5} \  \epsdice{6}}
     \end{description}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{$\chi^2$ tests}

   \begin{block}
     {Structure of a $\chi^2$ test}
     \begin{description}
     \item[Frequency table] The basic data, along with the expected counts.

     \begin{tabular}{c|c|c|p{1in}}
       {\small Value} & {\small Observed Count} & {\small Expected Count} \\ \hline
       1 & 4 & 10  \\
       2 & 6 & 10 \\
       3 & 17 & 10 \\
       4 & 16 & 10 \\
       5 & 8 & 10  \\
       6 & 9 & 10  \\ \hline
       Total & 60 & 60 \\
     \end{tabular}


     \item[{\color{orange} $\chi^2$} statistic] In this example, we computed it to be 14.2.
     \end{description}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{$\chi^2$ tests}

   \begin{block}
     {Structure of a $\chi^2$ test}
     \begin{description}
     \item[Degrees of freedom] In our example, this was 5 which was
     the number of ``free parameters.'' Call this number $df$.

     \item[$P$-value] Are from our observed $\chi^2$ statistic out to
     $\infty$
     under the $\chi^2_{df}$ probability histogram. This was about 1.4\% in our example.
     \end{description}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Testing independence:  another $\chi^2$ test}

   \begin{block}
     {Handedness and gender}
     \begin{itemize}
     \item Data example in book

       \begin{center}
     \begin{tabular}{c|c|c}
       Handedness & Male & Female \\ \hline
       Right & 934 & 1070 \\
       Left & 113 & 92 \\
       Ambidextrous & 20 & 8
     \end{tabular}
       \end{center}
       \item Is handedness related to gender (or not)?
     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Testing independence: another $\chi^2$ test}

   \begin{block}
     {Handedness and gender}
     \begin{itemize}
     \item There are two ``totals'' \dots, these are called {\em marginals}
     \begin{tabular}{c|c|c|c}
       Handedness & Male & Female & Total$_H$ \\ \hline
       Right & 934 & 1070 & 2004 \\
       Left & 113 & 92 & 205 \\
       Ambidextrous & 20 & 8 & 28 \\ \hline
       Total$_G$ & 1067 & 1170 & 2237
     \end{tabular}
     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Testing independence: another $\chi^2$ test}

   \begin{block}
     {Handedness and gender}
     \begin{itemize}
     \item The null hypothesis is {\color{blue} $H_0$: handedness is independent
     from gender}.
     \item This means that the probability a person (drawn at random)
     from the population is, say, a left-handed male, is the
     product of two probabilities: the probability a person
     is left-handed and the probability a person is male.
     \item Or,
     $$
     P(\text{left-handed \& male}) = P(\text{left-handed}) \times P(\text{male})
     $$
     \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % sys.path.append('/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf')
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % datadir ='/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf/data'
   % import numpy as np, pylab
   % import random
   % 
   % x = [195.66312, 221.61052, 157.35352, 231.13815, 13.34680, 110.02011,
   %      38.88158, 220.78335, 146.52131, 15.03196, 158.56636, 186.31249,
   %      152.84395, 54.18120, 42.15905,  43.25318, 187.95021]
   % y = [221.318958, 59.505313, 191.099571, 52.122050, 6.808426, 241.603658,
   %      76.207370, 162.056604, 140.111931, 102.609925, 24.479454, 75.126427,
   %      215.454302, 103.887709, 141.970066, 84.014976, 21.444533]
   % n=len(x)
   % X = np.array([x,y])
   % X = X.T
   % 
   % def sample_hand():
   %     x = ['L', 'R', 'A']
   %     np.random.shuffle(x)
   %     return x[0]
   % 
   % def sample_gender():
   %     x = ['M', 'F']
   %     np.random.shuffle(x)
   %     return x[0]
   % 
   % d = 8.
   % for i in range(15):
   %     pylab.fill_between([X[i,0]-d,X[i,0]], [X[i,1]-d,X[i,1]-d], [X[i,1]+.75*d,X[i,1]+.75*d], facecolor='green', alpha=0.5)
   %     pylab.fill_between([X[i,0],X[i,0]+d], [X[i,1]-d,X[i,1]-d], [X[i,1]+.75*d,X[i,1]+.75*d], facecolor='red', alpha=0.5)
   %     pylab.text(X[i,0]-d/2, X[i,1], sample_gender(), ha='center', va='center', size=10)
   %     pylab.text(X[i,0]+d/2, X[i,1], sample_hand(), ha='center', va='center', size=10)
   % pylab.gca().set_xticks([]); #   pylab.gca().set_xlim([-0.1,1.1])
   % pylab.gca().set_yticks([]); #   pylab.gca().set_ylim([-0.1,1.1])
   % 


   \begin{frame}
   \frametitle{Testing independence: another $\chi^2$ test}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/71b45848e7.pdf}}    
   \end{center}
   A sample of 17 from a large population
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Testing independence: another $\chi^2$ test}

   \begin{block}
     {Handedness and gender}
     \begin{itemize}
     \item Having specified the box, we can express ${\color{blue} H_0}$ via
     some equalities about the tickets in the box:
     $$
     \begin{aligned}
     p_{L,M} &= p_L \times p_M \\
     p_{R,M} &= p_R \times p_M \\
     p_{A,M} &= p_A \times p_M \\
     p_{L,F} &= p_L \times p_F \\
     p_{R,F} &= p_R \times p_F \\
     p_{A,F} &= p_A \times p_F \\
     \end{aligned}
     $$

     \item Some of these equalities are redundant. This affects the degrees of freedom.
     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Testing independence: another $\chi^2$ test}

   \begin{block}
     {Handedness and gender}
     \begin{itemize}
     \item If $H_0$ is true, the observed counts should
       follow a similar structure: the proportion of left-handed
       males should be close to the proportion of left-handed females, etc.
     \item This is our model for the {Expected} or $E$ part of the $\chi^2$
       statistic which we use to construct the frequency table.

     \item The sample proportion of men is {\color{orange} 48\%},
     the sample proportion of
     left-handed is {\color{orange} 9.2\%}.
     \item Under $H_0$, the independence model, we estimate that,
       in a sample of size 2237, we would see $2237 \times 0.48 \times 0.092 \approx 98$ left handed males.
     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Testing independence: another $\chi^2$ test}

   \begin{block}
     {Handedness and gender}
     \begin{itemize}
     \item Continuing for all 6 cases yields a table of
     ``Expected Counts''

     \begin{tabular}{c|c|c|c}
       Handedness & Male & Female & Total$_H$ \\ \hline
       Right & 956 & 1048 & 2004 \\
       Left & 98 & 107 & 205 \\
       Ambidextrous & 13 & 15 & 28 \\ \hline
       Total$_G$ & 1067 & 1170 & 2237
     \end{tabular}
     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Testing independence: another $\chi^2$ test}

   \begin{block}
     {Handedness and gender}
     \begin{itemize}
     \item The $\chi^2$ statistic is computed in exactly the same way
       $$
       \begin{aligned}
         \chi^2 &= \frac{(934-956)^2}{956} + \frac{(1070-1048)^2}{1048} +
          \frac{(113-98)^2}{98} \\
         & \qquad +  \frac{(92-107)^2}{107} + \frac{(20-13)^2}{13} + \frac{(8-15)^2}{15}  \\
         &\approx 12
       \end{aligned}
       $$
       \item
       In symbols,
       $$
       \chi^2 = \sum_{i=1}^3 \sum_{j=1}^2 \frac{(O_{ij}-E_{ij})^2}{E_{ij}}
       $$
     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Testing independence: another $\chi^2$ test}

   \begin{block}
     {Handedness and gender}
     \begin{itemize}
     \item This leaves the last two parts of the $\chi^2$ test: degrees of freedom and the $P$-value.
       \item The degrees of freedom for this test are actually only 2. This can be seen in the difference table


     \begin{tabular}{c|c|c|c}
       Handedness & Male & Female & Total$_H$ \\ \hline
       Right & -22 & 22 & 0 \\
       Left & 15 & -15 & 0 \\
       Ambidextrous & 7 & -7 & 0 \\ \hline
       Total$_G$ & 0 & 0 & 0
     \end{tabular}

     \item By construction all the marginal totals of the difference table
     are 0. So, we can set two of the values freely \dots

     \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % sys.path.append('/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf')
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % datadir ='/private/var/folders/dq/4_9bwd013ln6vvf_q110mwrh0000gn/T/tmpRJSbVf/data'
   % import pylab, numpy as np
   % import scipy.stats
   % df = 2
   % x = np.linspace(10,20,101)
   % y = scipy.stats.chi2.pdf(x, df)
   % x2 = np.linspace(12,20,101)
   % y2 = scipy.stats.chi2.pdf(x2, df)
   % pylab.plot(x,y*100, linewidth=2)
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='red', hatch='\\', alpha=0.5)
   % pylab.gca().set_xlabel('standardized units')
   % pylab.gca().set_ylabel('% per standardized unit')
   % pylab.title('The area is about %0.1f%%' % (100 * scipy.stats.chi2.sf(12, df)))
   % 


   \begin{frame}
   \frametitle{$\chi^2_2$ probability histogram}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/d5ccea2495.pdf}}    
   \end{center}

   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} 

   \end{frame}

   \end{document}
