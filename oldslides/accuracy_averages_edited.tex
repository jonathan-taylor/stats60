   \documentclass[handout]{beamer}



   \mode<presentation>
   {
     \usetheme{PaloAlto}
   \setbeamertemplate{footline}[page number]

     \setbeamercolor{sidebar}{bg=white, fg=black}
     \setbeamercolor{frametitle}{bg=white, fg=black}
     % or ...
     \setbeamercolor{logo}{bg=white}
     \setbeamercolor{block body}{parent=normal text,bg=white}
     \setbeamercolor{author in sidebar}{fg=black}
     \setbeamercolor{title in sidebar}{fg=black}


     \setbeamercolor*{block title}{use=structure,fg=structure.fg,bg=structure.fg!20!bg}
     \setbeamercolor*{block title alerted}{use=alerted text,fg=alerted text.fg,bg=alerted text.fg!20!bg}
     \setbeamercolor*{block title example}{use=example text,fg=example text.fg,bg=example text.fg!20!bg}


     \setbeamercolor{block body}{parent=normal text,use=block title,bg=block title.bg!50!bg}
     \setbeamercolor{block body alerted}{parent=normal text,use=block title alerted,bg=block title alerted.bg!50!bg}
     \setbeamercolor{block body example}{parent=normal text,use=block title example,bg=block title example.bg!50!bg}

     % or ...

     \setbeamercovered{transparent}
     % or whatever (possibly just delete it)
     \logo{\resizebox{!}{1.5cm}{\href{\basename{R}}{\includegraphics{image}}}}
   }

   \mode<handout>
   {
     \usetheme{PaloAlto}
     \usecolortheme{default}
     \setbeamercolor{sidebar}{bg=white, fg=black}
     \setbeamercolor{frametitle}{bg=white, fg=black}
     % or ...
     \setbeamercolor{logo}{bg=white}
     \setbeamercolor{block body}{parent=normal text,bg=white}
     \setbeamercolor{author in sidebar}{fg=black}
     \setbeamercolor{title in sidebar}{fg=black}
     \setbeamercovered{transparent}
     % or whatever (possibly just delete it)
     \logo{}
   }

   \usepackage{epsdice}
   \usepackage[latin1]{inputenc}
   \usepackage{graphics}
   \usepackage{amsmath,eepic,epic}

   \newcommand{\figslide}[3]{
   \begin{frame}
   \frametitle{#1}
     \begin{center}
     \resizebox{!}{2.7in}{\includegraphics{#2}}    
     \end{center}
   {#3}
   \end{frame}
   }

   \newcommand{\fighslide}[4]{
   \begin{frame}
   \frametitle{#1}
     \begin{center}
     \resizebox{!}{#4}{\includegraphics{#2}}    
     \end{center}
   {#3}
   \end{frame}
   }

   \newcommand{\figwref}[1]{
   \href{#1}{\tiny \tt #1}}

   \newcommand{\B}[1]{\beta_{#1}}
   \newcommand{\Bh}[1]{\widehat{\beta}_{#1}}
   \newcommand{\V}{\text{Var}}
   \newcommand{\Cov}{\text{Cov}}
   \newcommand{\Vh}{\widehat{\V}}
   \newcommand{\s}{\sigma}
   \newcommand{\sh}{\widehat{\sigma}}

   \newcommand{\argmax}[1]{\mathop{\text{argmax}}_{#1}}
   \newcommand{\argmin}[1]{\mathop{\text{argmin}}_{#1}}
   \newcommand{\Ee}{\mathbb{E}}
   \newcommand{\Pp}{\mathbb{P}}
   \newcommand{\real}{\mathbb{R}}
   \newcommand{\Ybar}{\overline{Y}}
   \newcommand{\Yh}{\widehat{Y}}
   \newcommand{\Xbar}{\overline{X}}
   \newcommand{\Tr}{\text{Tr}}


   \newcommand{\model}{{\cal M}}

   \newcommand{\figvskip}{-0.7in}
   \newcommand{\fighskip}{-0.3in}
   \newcommand{\figheight}{3.5in}

   \newcommand{\Rcode}[1]{{\bf \tt #1 }}
   \newcommand{\Rtcode}[1]{{\tiny \bf \tt #1 }}
   \newcommand{\Rscode}[1]{{\small \bf \tt #1 }}

   \newcommand{\RR}{{\tt R} \;}
   \newcommand{\basename}[1]{http://stats60.stanford.edu/#1}
   \newcommand{\dataname}[1]{\basename{data/#1}}
   \newcommand{\Rname}[1]{\basename{R/#1}}

   \newcommand{\mycolor}[1]{{\color{blue} #1}}
   \newcommand{\basehref}[2]{\href{\basename{#1}}{\mycolor{#2}}}
   \newcommand{\Rhref}[2]{\href{\basename{R/#1}}{\mycolor{#2}}}
   \newcommand{\datahref}[2]{\href{\dataname{#1}}{\mycolor{#2}}}
   \newcommand{\X}{\pmb{X}}
   \newcommand{\Y}{\pmb{Y}}
   \newcommand{\be}{\pmb{varepsilon}}
   \newcommand{\logit}{\text{logit}}


   \title{Statistics 60: Introduction to Statistical Methods}
   \subtitle{Chapter 23 \& 24: The accuracy of averages and the Gauss model} 
   \author{}% {Jonathan Taylor \\
   %Department of Statistics \\
   %Stanford University
   %}


   \begin{document}

   \begin{frame}
   \titlepage
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Average of draws from a box}

   \begin{block}
   {Average of draws}
   \begin{itemize}
   \item Earlier, we saw how to compute the SE for the sum of draws from a box.
   \item The {\em average of the draws} is
   $$
   \text{\bf average of draws} = \frac{\text{\bf sum of draws}}{\text{{\bf $\#$ of draws}}}
   $$

   \item Dividing by the $\#$ of draws changes the expected value and the SE.
   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Average of draws from a box}

   \begin{block}
   {Accuracy of {\bf average of draws}}
   \begin{itemize}
   \item The expected value is the average of the box
   $$
   \text{E({\bf average of draws})} = \text{\bf average of box}
   $$

   \item The SE is
   $$
   \begin{aligned}
      \text{SE({\bf average of draws})} &= \frac{\text{SE({\bf sum of draws})}}{\text{$\#$ of draws}}      \\
      &= \frac{\sqrt{\text{$\#$ of draws}} \times \text{SD({\bf box})}}{{\text{$\#$ of draws}}}      \\
      &= \frac{\text{SD({\bf box})}}{\sqrt{\text{$\#$ of draws}}}      \\
   \end{aligned}
   $$
   \item Just like the SE of sample proportion -- it decreases as \# draws increase.
   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % dx = 0.02
   % X, Y = np.mgrid[0.2:0.8:5j,0:1:8j]
   % X += np.random.uniform(0,1,X.shape) * dx - dx / 2
   % Y += np.random.uniform(0,1,Y.shape) * dx - dx / 2
   % ts = range(1,37) + ['0', '00']
   % success = [5]
   % tt = [('-10\$', 'yellow')] * 38
   % for r in success:
   %     tt[r] = ('+350\$', 'pink')
   % #np.random.shuffle(tt)
   % X.shape = -1; Y.shape = -1
   % g = np.array([t[1] == 'pink' for t in tt])
   % pylab.scatter(X[:38][g],Y[:38][g],s=700, c='red')
   % pylab.scatter(X[:38][~g],Y[:38][~g],s=700, c='yellow')
   % for i, t in enumerate(tt):
   %     pylab.text(X[i], Y[i], t[0], color='black', ha='center', va='center',
   %                fontsize=10)
   % 
   % pylab.gca().set_xticks([])
   % pylab.gca().set_yticks([])
   % pylab.gca().set_xlim([X.min()-0.1,X.max()+0.1])
   % pylab.gca().set_ylim([Y.min()-0.1,Y.max()+0.2])
   % 


   \begin{frame}
   \frametitle{Example of a box model}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/ee2884116d.pdf}}    
   \end{center}
   Betting 10\$ on {\color{red} 5}: win 350\$ with probability 1/38
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % p = 1./38
   % n = 10
   % x, p = conv_binom(p, n)
   % cp = np.cumsum(p)
   % k = (cp >= 0)
   % XX = np.zeros(x.shape[0]+1)
   % XX[:-1] = 350 * x - 10 * (n - x)
   % XX[-1] = XX[-2] + 100
   % PL_density(p, XX-170)
   % pylab.gca().set_xlim([-400,1200])
   % pylab.gca().set_ylabel('$\%$ per \$')
   % pylab.gca().set_xlabel('\$')
   % 


   \begin{frame}
   \frametitle{Probability histogram of successes}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/16d14a41d0.pdf}}    
   \end{center}
   Betting on {\color{red} 5} 10 times,  total earnings.
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % p = 1./38
   % n = 10
   % x, p = conv_binom(p, n)
   % cp = np.cumsum(p)
   % k = (cp >= 0)
   % XX = np.zeros(x.shape[0]+1)
   % XX[:-1] = (350 * x - 10 * (n - x))
   % XX[-1] = XX[-2] + 100
   % PL_density(p, (XX-170.)/n)
   % pylab.gca().set_xlim([-400./n,1200./n])
   % pylab.gca().set_ylabel('$\%$ per \$')
   % pylab.gca().set_xlabel('\$')
   % 


   \begin{frame}
   \frametitle{Probability histogram of successes}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/4673806cdb.pdf}}    
   \end{center}
   Betting on {\color{red} 5} 10 times, average earnings.
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % p = 1./38
   % n = 100
   % x, p = conv_binom(p, n)
   % cp = np.cumsum(p)
   % k = (cp >= 0)
   % XX = np.zeros(x.shape[0]+1)
   % XX[:-1] = 350 * x - 10 * (n - x)
   % XX[-1] = XX[-2] + 100
   % PL_density(p, XX-170)
   % pylab.gca().set_ylabel('$\%$ per \$')
   % pylab.gca().set_xlim([-1000,3000])
   % pylab.gca().set_xlabel('\$')
   % 


   \begin{frame}
   \frametitle{Probability histogram of successes}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/02fc5cc99e.pdf}}    
   \end{center}
   Betting on {\color{red} 5} 100 times,  total earnings.
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % p = 1./38
   % n = 100
   % x, p = conv_binom(p, n)
   % cp = np.cumsum(p)
   % k = (cp >= 0)
   % XX = np.zeros(x.shape[0]+1)
   % XX[:-1] = 350 * x - 10 * (n - x)
   % XX[-1] = XX[-2] + 100
   % PL_density(p, (XX-170)/n)
   % pylab.gca().set_ylabel('$\%$ per \$')
   % pylab.gca().set_xlim([-1000./n,3000./n])
   % pylab.gca().set_xlabel('\$')
   % 


   \begin{frame}
   \frametitle{Probability histogram of successes}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/6472dc65d9.pdf}}    
   \end{center}
   Betting on {\color{red} 5} 100 times, average earnings
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % p = 1./38
   % n = 1000
   % x, p = conv_binom(p, n)
   % cp = np.cumsum(p)
   % k = (cp >= 0)
   % XX = np.zeros(x.shape[0]+1)
   % XX[:-1] = 350 * x - 10 * (n - x)
   % XX[-1] = XX[-2] + 100
   % PL_density(p, XX-170)
   % pylab.gca().set_ylabel('$\%$ per \$')
   % pylab.gca().set_xlim([-6000,6000])
   % pylab.gca().set_xlabel('\$')
   % 


   \begin{frame}
   \frametitle{Probability histogram of successes}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/4e88bd91d1.pdf}}    
   \end{center}
   Betting on {\color{red} 5} 1000 times,  total earnings.
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % p = 1./38
   % n = 1000
   % x, p = conv_binom(p, n)
   % cp = np.cumsum(p)
   % k = (cp >= 0)
   % XX = np.zeros(x.shape[0]+1)
   % XX[:-1] = 350 * x - 10 * (n - x)
   % XX[-1] = XX[-2] + 100
   % PL_density(p, (XX-170)/n)
   % pylab.gca().set_ylabel('$\%$ per \$')
   % pylab.gca().set_xlim([-6000./n, 6000./n])
   % pylab.gca().set_xlabel('\$')
   % 


   \begin{frame}
   \frametitle{Probability histogram of successes}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/bf0e22d7e2.pdf}}    
   \end{center}
   Betting on {\color{red} 5} 1000 times, average earnings
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % p = 1./38
   % n = 10000
   % x, p = conv_binom(p, n)
   % cp = np.cumsum(p)
   % k = (cp >= 0)
   % XX = np.zeros(x.shape[0]+1)
   % XX[:-1] = 350 * x - 10 * (n - x)
   % XX[-1] = XX[-2] + 100
   % PL_density(p, (XX-170))
   % pylab.gca().set_ylabel('$\%$ per \$')
   % pylab.gca().set_xlim([-20000,10000])
   % pylab.gca().set_xlabel('\$')
   % 


   \begin{frame}
   \frametitle{Probability histogram of successes}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/7216bada84.pdf}}    
   \end{center}
   Betting on {\color{red} 5} 10000 times, total earnings.
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % p = 1./38
   % n = 10000
   % x, p = conv_binom(p, n)
   % cp = np.cumsum(p)
   % k = (cp >= 0)
   % XX = np.zeros(x.shape[0]+1)
   % XX[:-1] = 350 * x - 10 * (n - x)
   % XX[-1] = XX[-2] + 100
   % PL_density(p, (XX-170)/n)
   % pylab.gca().set_ylabel('$\%$ per \$')
   % pylab.gca().set_xlim([-20000./n,10000./n])
   % pylab.gca().set_xlabel('\$')
   % 


   \begin{frame}
   \frametitle{Probability histogram of successes}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/f90ba01137.pdf}}    
   \end{center}
   Betting on {\color{red} 5} 10000 times, average earnings.
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % dx = 0.02
   % X, Y = np.mgrid[0.2:0.8:5j,0:1:8j]
   % X += np.random.uniform(0,1,X.shape) * dx - dx / 2
   % Y += np.random.uniform(0,1,Y.shape) * dx - dx / 2
   % ts = range(1,37) + ['0', '00']
   % success = [5]
   % tt = [('?', 'gray')] * 38
   % #for r in success:
   % #    tt[r] = ('+350\$', 'pink')
   % #np.random.shuffle(tt)
   % X.shape = -1; Y.shape = -1
   % g = np.array([t[1] == 'pink' for t in tt])
   % pylab.scatter(X[:38],Y[:38],s=700, c='gray')
   % #pylab.scatter(X[:38][~g],Y[:38][~g],s=700, c='yellow')
   % for i, t in enumerate(tt):
   %     pylab.text(X[i], Y[i], t[0], color='black', ha='center', va='center',
   %                fontsize=10)
   % 
   % pylab.gca().set_xticks([])
   % pylab.gca().set_yticks([])
   % pylab.gca().set_xlim([X.min()-0.1,X.max()+0.1])
   % pylab.gca().set_ylim([Y.min()-0.1,Y.max()+0.2])
   % 


   \begin{frame}
   \frametitle{Box we actually sample from \dots}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/a5295f233d.pdf}}    
   \end{center}
   We may not even know how many balls there are \dots
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % initial = 0.
   % 
   % results = []
   % n = 10
   % for _ in range(20000):
   %     draws = np.random.binomial(n, 1/38.)
   %     results.append((initial + 350 * draws - 10. * (n - draws)) / n)
   % 
   % pylab.hist(results, bins=10, facecolor='orange')
   % results = np.array(results)
   % pylab.title("average=%0.2f, SD=%0.2f" % ((results.mean()), (results.std())))
   % 


   \begin{frame}
   \frametitle{Sample of 10 with replacement}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/0a939c3a8f.pdf}}    
   \end{center}
   Average of 10 draws with replacement, repeated 20000 times
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % initial = 0.
   % 
   % results = []
   % n = 100
   % for _ in range(20000):
   %     draws = np.random.binomial(n, 1/38.)
   %     results.append((initial + 350 * draws - 10. * (n - draws)) / n)
   % 
   % pylab.hist(results, bins=10, facecolor='orange')
   % results = np.array(results)
   % pylab.title("average=%0.2f, SD=%0.2f" % ((results.mean()), (results.std())))
   % 


   \begin{frame}
   \frametitle{Sample of 100 with replacement}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/40983df370.pdf}}    
   \end{center}
   Average of 100 draws with replacement, repeated 20000 times
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % initial = 0.
   % 
   % results = []
   % n = 1000
   % for _ in range(20000):
   %     draws = np.random.binomial(n, 1/38.)
   %     results.append((initial + 350 * draws - 10. * (n - draws)) / n)
   % 
   % pylab.hist(results, bins=20, facecolor='orange')
   % results = np.array(results)
   % pylab.title("average=%0.2f, SD=%0.2f" % ((results.mean()), (results.std())))
   % 


   \begin{frame}
   \frametitle{Sample of 1000 with replacement}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/fadc847c6d.pdf}}    
   \end{center}
   Average of 1000 draws with replacement, repeated 20000 times
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % initial = 0.
   % 
   % results = []
   % n = 10000
   % for _ in range(20000):
   %     draws = np.random.binomial(n, 1/38.)
   %     results.append((initial + 350 * draws - 10. * (n - draws)) / n)
   % 
   % pylab.hist(results, bins=20, facecolor='orange')
   % results = np.array(results)
   % pylab.title("average=%0.2f, SD=%0.2f" % ((results.mean()), (results.std())))
   % 


   \begin{frame}
   \frametitle{Sample of 10000 with replacement}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/b31bf477bd.pdf}}    
   \end{center}
   Average of 10000 draws with replacement, repeated 20000 times
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Estimating SE when content of box is unknown}

   \begin{block}
   {Accuracy of averages second statistic}
   \begin{itemize}
   \item Given a sample ${\color{orange}[X_1, \dots, X_n]}$ of $n$ draws, we can compute the {\em sample mean}
   Call this
   $$
   {\color{orange} \bar{X}}  = \frac{{\color{orange} \text{\bf sum of draws}}}{{\color{blue} \text{$\#$ of draws}}}  = \frac{{\color{orange} \sum_{i=1}^n X_i}}{{\color{blue} n}}
   $$
   \item We know
   $$
   \begin{aligned}
   {\color{blue} \text{SE}(\bar{X})} = \frac{{\color{blue}\text{SD({\bf box})}}}{{\color{blue} \sqrt{\text{$\#$ of draws}}}}
   \end{aligned}
   $$

   \item Unfortunately, we don't know ${\color{blue}\text{SD({\bf box})}}$.

   \item Use {\color{orange} plug-in / bootstrap} estimate
   $$
   {\color{orange}\widehat{ \text{SE}(\bar{X})}} = \frac{{\color{orange}\text{SD($[X_1, \dots, X_n]$)}}}{{\color{blue}\sqrt{ \text{$\#$ of draws}}}} =  \frac{{\color{orange} \sqrt{\frac{1}{n}\sum_{i=1}^n (X_i - \bar{X})^2}}}{\color{blue} \sqrt{n}}
   $$

   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Estimating {\color{blue} average({\bf box})}}

   \begin{block}
   {Normal approximation}
   \begin{itemize}
   \item Conversion to average just changes the units.
   \item We can use normal approximation to approximate chances,
   as long as we standardize correctly.

   \item For example, there is 90\% probability that
   $\color{orange}\bar{X}$ is within ${ \color{blue} \pm 1.65 \ \color{blue}\text{SD({\bf box})} / \sqrt{n}}$ of {\color{blue} average({\bf box})}.

   \item Call  ${\color{blue} \text{average}({\bf box})= \mu}$, the {\color{blue} population average}.
   \item The parameter ${\color{blue} \mu}$ is determined by the chance process. It is not random, it is a number.
   \item How can we ``reverse this statement'' to yield a confidence interval
   based on a sample of, say, size 100 for ${\color{blue} \mu}$?

   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Confidence interval for {\color{blue} average({\bf box})}}

   \begin{block}
   {Reversing the picture}
   \begin{itemize}
   \item The normal approximation says, for a sample of size 100
   $$
   \begin{aligned}
   \text{P} \left(\text{$\bar{X} > \mu + \frac{1.65 \times \; \text{SD({\bf box})}}{\sqrt{100}}$}\right) &\approx 5\% \\
   \text{P} \left(\text{$\bar{X} < \mu - \frac{1.65 \times \; \text{SD({\bf box})}}{\sqrt{100}}$}\right) &\approx 5\% \\
   \end{aligned}
   $$
   \item This is the same as saying
   $$
   \begin{aligned}
   \text{P} \left(\text{$\mu < \bar{X} - \frac{1.65 \times \; \text{SD({\bf box})}}{\sqrt{100}}$}\right) &\approx 5\% \\
   \text{P} \left(\text{$ \mu > \bar{X} + \frac{1.65 \times \; \text{SD({\bf box})}}{\sqrt{100}}$}\right) &\approx 5\% \\
   \end{aligned}
   $$
   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Confidence intervals}

   \begin{block}
   {Reversing the picture}
   \begin{itemize}
   \item In other words,
   $$
   \begin{aligned}
   \text{P} \left(\text{$\mu$ between $\bar{X} \pm 1.65 \times \frac{\text{SD({\bf box})}}{\sqrt{100}}$} \right) &\approx 90\% \\
   \end{aligned}
   $$
   \item Or, color-coded
   $$
   \begin{aligned}
   \text{P} \left(\text{${\color{blue} \mu}$ between ${\color{orange} \bar{X}} \pm {\color{blue} 1.65 \times \frac{\text{SD({\bf box})}}{\sqrt{100}}}$} \right) &\approx 90\% \\
   \end{aligned}
   $$
   \item If we knew ${\color{blue} \text{SD}({\bf box})}$ we would have an interval on the right based
   on the {\color{orange} sample mean} that says something about
   {\color{blue} $\mu$=average({\bf box})}.
   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Confidence intervals}

   \begin{block}
   {Using our bootstrap estimate of SE}
   \begin{itemize}
   \item Even though we don't know ${\color{blue} SD({\bf box})}$ we estimated
   $$
   \frac{\color{blue} \text{SD}({\bf box})}{{\color{blue} \sqrt{100}}}
   $$
   by the bootstrap estimate of SE
   $$
   \frac{{\color{orange} \text{SD}([X_1, \dots, X_{100}])}}{{\color{orange} \sqrt{100}}} = \frac{{\color{orange} \sqrt{\frac{1}{100}\sum_{i=1}^{100} (X_i - \bar{X})^2}}}{\color{orange} \sqrt{100}}
   $$
   \item If we can plug this in (and we can if sample is large enough), we see that
   $$
   \begin{aligned}
   \text{P} \left(\text{${\color{blue} \mu}$ between ${\color{orange} \bar{X} \pm 1.65 \times \; \text{SD}([X_1, \dots, X_{100}]) / \sqrt{100}}$}\right) &\approx 90\% \\
   \end{aligned}
   $$

   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Different SE}

   \begin{block}
     {Different SE}
     \begin{itemize}
     \item We have seen various different rules for computing SE.
       \begin{itemize}
       \item $\text{SE({\bf sum of draws})} = \sqrt{\text{$\#$ of draws}} \times \text{SD}({\bf box})$
       \item $\text{SE({\bf average of draws})} = \text{SE({\bf sum of draws})} / \text{$\#$ of draws}$
       \item $\text{SE}({\bf count}) =  \text{SE({\bf sum of draws from 0-1 box})}$
       \item $\text{SE({\bf proportion})} =  \text{SE({\bf sum of draws from 0-1 box})} / {\text{$\#$ of draws}}$
       \end{itemize}
     \item They are all examples of the first $\text{SE({\bf sum of draws})}$ followed by unit conversion.
      \item Once we have figured out the appropriate SE and expected value,
     we can use normal approximation if $\#$ of draws is large enough.
     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Normal approximation}

   \begin{block}
     {Normal approximation for ${\color{orange} \widehat{\theta}}$}
     \begin{itemize}
     \item Suppose we are trying to estimate {\em something} called
     ${\color{blue} \theta}$ with an estimator ${\color{orange} \widehat{\theta}}$.
     \item Under the appropriate conditions, a normal approximation may hold ${\color{orange} \widehat{\theta}}$.
     \item If ${\color{orange} \widehat{\theta}} = {\color{blue} \theta}$ and the normal approximation holds, then
     $$
     P \left(\frac{{\color{orange}  \widehat{\theta}} - {\color{blue} \theta}}{{{\color{blue} \text{SE}}} ({\color{orange} \widehat{\theta}})} \leq c \right)
     $$
     can be expressed as the area under the standard normal curve, i.e.
     it can be computed using table A-104 from the book.
     \item For example, suppose $c=-1.5$, then \dots

     \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % import pylab, numpy as np
   % x = np.linspace(-4,4,101)
   % y = np.exp(-x**2/2) / np.sqrt(2*np.pi)
   % x2 = np.linspace(-4,-1.5,101)
   % y2 = np.exp(-x2**2/2) / np.sqrt(2*np.pi)
   % pylab.plot(x,y*100, linewidth=2)
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='red', hatch='\\', alpha=0.5)
   % pylab.text(-1.5, 15, r'$c=-1.5$', ha='center', size=20)
   % pylab.gca().set_xlabel('standardized units')
   % pylab.gca().set_ylabel('% per standardized unit')
   % #pylab.gca().set_xlim([-2,4])
   % #pylab.gca().set_yticks([])
   % 


   \begin{frame}
   \frametitle{Normal approximation}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/9abd74e91b.pdf}}    
   \end{center}
   From A-104, chances are approximately 6.7\%
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Normal approximation}

    \begin{block}
     {Normal approximation and confidence intervals}
     \begin{itemize}
     \item If a normal approximation holds
       for ${\color{orange} \widehat{\theta}}$
       then, for example,
       $$
       {\color{orange} \widehat{\theta}} \pm 1.65 \times {\color{blue} \text{SE}}({\color{orange} \widehat{\theta}})
       $$
       is a 90\% confidence interval for ${\color{blue} \theta}=E({\color{orange} \widehat{\theta}})$.

      \item Often, we only have an estimate ${\color{orange} \widehat{ \text{SE}(\widehat{\theta})}}$ of ${\color{blue} SE}({\color{orange} \widehat{\theta}})$.
       \item We can then compute an approximate 90\% confidence interval:
       $$
       {\color{orange} \widehat{\theta}} \pm 1.65 \times {\color{orange} \widehat{ \text{SE}(\widehat{\theta})}}
      $$
      \item {\color{red} \bf Caution: if the normal approximation does not
     hold, then we
     cannot use these rules for confidence intervals.}

     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Normal approximation}

    \begin{block}
     {Example}
     \begin{description}
       \item[Q] Suppose you ask a consultant to estimate
      the the long run average of the daily sales of your business.
      By some method,
      he estimates the sales and tells you:
      ``{\em
        I estimate your long run average of daily sales to
        be \$ 2100 give or take
        \$ 200.}''
      Find a 95\% confidence interval for your average daily sales.
     \end{description}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Normal approximation}

    \begin{block}
     {Example}
     \begin{description}
       \item[A] We do not have enough information yet to determine
      it the method the consultant used is such that a normal
      approximation holds.
       When asked, he tells you ``{\em My methodology is simple: I just took the sales from yesterday, which were \$2100 and figured \$200 dollars is a reasonable give or take number}.''

      Your response:
      \begin{quote}
        You're fired \dots
      \end{quote}
     \end{description}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Normal approximation}

    \begin{block}
     {Example}
     \begin{description}
      \item[Q] The next consultant you hire gives you an estimate
      of \$ 2050 give or take \$ 250 and he assures you
      that his methodology is such that a normal approximation is reasonable.
      Find a 95\% confidence interval for the long run average daily sales.
       \item[A] A 95\% confidence interval for the long run average
       daily sales is
       $$
       \$ 2050 \pm 2 \times \$ 250.
       $$
     \end{description}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Gauss model}

   \begin{block}
     {Measurement models and draws from a box}
     \begin{itemize}
     \item We have seen how to deal with average from a box.
     \item Not all measurements in reality fit this model, so our
      SE rules do not apply.
     \item Examples:
       \begin{itemize}
       \item Population of U.S. by year: it is always increasing.
       \item Daily max temperature in Palo Alto: there is a seasonal trend in it.
       \end{itemize}
     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{US Population}

   \begin{figure}
   \centering
   \resizebox{!}{2.6in}{\includegraphics{figs/descriptive/population}}
   \end{figure}

   \href{http://news.bbc.co.uk/2/hi/6057004.stm}{BBC}
   \end{frame}

   %CODE
       % PA.temp <- read.table('http://www-stat.stanford.edu/~jtaylo/courses/stats191/data/paloaltoT.table', header=F, skip=2)
   % plot(PA.temp[,3], xlab='Day', ylab='Average Max Temp (F)', pch=23, bg='orange')


   \begin{frame}
   \frametitle{Average Max Temp in Palo Alto}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/4a013ee86e.png}}    
   \end{center}

   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Gauss model}

   \begin{block}
     {Gauss model}
     \begin{itemize}
     \item The Gauss model assume that each measurement has the form
     $$
     {\color{orange} \text{measurement}} = {\color{blue} \text{true value}} + {\color{orange} \text{chance error}}
     $$
     \item When the Gauss model holds, taking a measurement corresponds
     to drawing from an {\color{orange} error box} and adding
     a {\color{blue} true value}.

     \item If the measurement is biased, the Gauss model is
     $$
     {\color{orange} \text{measurement}} = {\color{blue} \text{true value}} + {\color{purple} \text{bias}} + {\color{orange} \text{chance error}}
     $$

     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Gauss model}

   \begin{block}
     {Gauss model}
     \begin{itemize}
     \item Suppose we observe ${\color{orange} [X_1, \dots, X_n]}$ from the Gauss model.
     \item Then,
     $$
     \begin{aligned}
     E({\color{orange} \bar{X}}) &= {\color{blue} \text{true value}} \\
     \text{SE}({\color{orange} X_1}) &= \text{SE}({\color{orange} \text{one draw from error box}}) \\
     \text{SE}({\color{orange} \bar{X}}) &= \frac{1}{\sqrt{n}} \text{SE}({\color{orange} \text{one draw from error box}}) \\
     \end{aligned}
     $$
     \item A reasonable estimate of $\text{SE}({\color{orange} \bar{X}})$ is
     $$
     {\color{orange} \widehat{SE({\color{orange} \bar{X}})}} = \frac{1}{\sqrt{n}} \text{SD}({\color{orange} [X_1, \dots, X_n]}).
     $$
     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Gauss model}

   \begin{block}
     {No box, no inference}
     \begin{itemize}
     \item If you can't accurately describe your chance process as
     drawing from a box
     you can't use these formulae for SE because they were all
     based on drawing from a box.

     \item Example: suppose that you have some problem with your
     computer and instead of inserting the draw from a box only once
     in your list, it inserts it twice. You draw until you reach
     a fixed number of elements in the list, say, 100.
     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Gauss model}

   \begin{block}
     {Example (continued)}
     \begin{itemize}
     \item Suppose the box is [1,3,5] and you observe $[1,1,3,3,5,5]$.
     The usual estimate for the SE for a sum of 6 draws will
     yield an estimated ${\color{blue} \text{SD(box)}}$ of
     $$
     {\color{orange} \widehat{\text{SD(box)}}} = \sqrt{\frac{1}{6} (2 \times (-2)^2 + 2 \times 0^2 + 2 \times 2^2)} = 1.63
     $$
     \item The bootstrap rule for estimating {\color{blue} SE(sum of 6 draws from box)} will yield
       $$
       {\color{orange} \widehat{\text{SE(sum of 6 draws)}}} = \sqrt{6} \times 1.63 = \sqrt{6} \times \sqrt{\frac{16}{6}} = 4.
       $$

     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Gauss model}

   \begin{block}
     {Example (continued)}
     \begin{itemize}
     \item {\bf \color{red} But}, the sum of these 6 draws is actually like twice the
     sum of 3 draws. So its SE is
     $$
     2 \times \sqrt{3} \times {\color{blue} \text{SD(box)}} = 2 \times \sqrt{3} \times \sqrt{8} = 5.65
     $$
     So we will have underestimated the actual SE.

     \item This is not an artifact of only taking 6 draws.
     \item Ignoring the duplicates will yield an estimate that is too
     small by a factor of $1/\sqrt{2}$.
     \item The normal approximation will still hold for the sum
       of draws with duplicates, but we will have the wrong SE.
     \item Our confidence intervals will be too small!
     \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % f=pylab.gcf(); f.set_size_inches(8.0,6.0)
   % import pylab, numpy as np, random
   % def sample():
   %     X = [random.randint(0,2)*2+1 for _ in range(50)]
   %     return np.sqrt(100) * np.array(2*X).std(), np.array(2*X).sum()
   % 
   % results = [sample() for _ in range(2000)]
   % results = np.array(results)
   % pylab.hist(results[:,0], bins=20, facecolor='orange')
   % actual = np.std(results[:,1])
   % pylab.title("average(estimated SE)=%0.2f, actual=%0.2f" % ((results[:,0].mean()), actual))
   % 


   \begin{frame}
   \frametitle{Gauss model}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/14f9cd7240.pdf}}    
   \end{center}
   Standard error estimated in duplicates model
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} 

   \end{frame}

   \end{document}
