   \documentclass[handout]{beamer}



   \mode<presentation>
   {
     \usetheme{PaloAlto}
   \setbeamertemplate{footline}[page number]

     \setbeamercolor{sidebar}{bg=white, fg=black}
     \setbeamercolor{frametitle}{bg=white, fg=black}
     % or ...
     \setbeamercolor{logo}{bg=white}
     \setbeamercolor{block body}{parent=normal text,bg=white}
     \setbeamercolor{author in sidebar}{fg=black}
     \setbeamercolor{title in sidebar}{fg=black}


     \setbeamercolor*{block title}{use=structure,fg=structure.fg,bg=structure.fg!20!bg}
     \setbeamercolor*{block title alerted}{use=alerted text,fg=alerted text.fg,bg=alerted text.fg!20!bg}
     \setbeamercolor*{block title example}{use=example text,fg=example text.fg,bg=example text.fg!20!bg}


     \setbeamercolor{block body}{parent=normal text,use=block title,bg=block title.bg!50!bg}
     \setbeamercolor{block body alerted}{parent=normal text,use=block title alerted,bg=block title alerted.bg!50!bg}
     \setbeamercolor{block body example}{parent=normal text,use=block title example,bg=block title example.bg!50!bg}

     % or ...

     \setbeamercovered{transparent}
     % or whatever (possibly just delete it)
     \logo{\resizebox{!}{1.5cm}{\href{\basename{R}}{\includegraphics{image}}}}
   }

   \mode<handout>
   {
     \usetheme{PaloAlto}
     \usecolortheme{default}
     \setbeamercolor{sidebar}{bg=white, fg=black}
     \setbeamercolor{frametitle}{bg=white, fg=black}
     % or ...
     \setbeamercolor{logo}{bg=white}
     \setbeamercolor{block body}{parent=normal text,bg=white}
     \setbeamercolor{author in sidebar}{fg=black}
     \setbeamercolor{title in sidebar}{fg=black}
     \setbeamercovered{transparent}
     % or whatever (possibly just delete it)
     \logo{}
   }

   \usepackage{epsdice}
   \usepackage[latin1]{inputenc}
   \usepackage{graphics}
   \usepackage{amsmath,eepic,epic}

   \newcommand{\figslide}[3]{
   \begin{frame}
   \frametitle{#1}
     \begin{center}
     \resizebox{!}{2.7in}{\includegraphics{#2}}    
     \end{center}
   {#3}
   \end{frame}
   }

   \newcommand{\fighslide}[4]{
   \begin{frame}
   \frametitle{#1}
     \begin{center}
     \resizebox{!}{#4}{\includegraphics{#2}}    
     \end{center}
   {#3}
   \end{frame}
   }

   \newcommand{\figwref}[1]{
   \href{#1}{\tiny \tt #1}}

   \newcommand{\B}[1]{\beta_{#1}}
   \newcommand{\Bh}[1]{\widehat{\beta}_{#1}}
   \newcommand{\V}{\text{Var}}
   \newcommand{\Cov}{\text{Cov}}
   \newcommand{\Vh}{\widehat{\V}}
   \newcommand{\s}{\sigma}
   \newcommand{\sh}{\widehat{\sigma}}

   \newcommand{\argmax}[1]{\mathop{\text{argmax}}_{#1}}
   \newcommand{\argmin}[1]{\mathop{\text{argmin}}_{#1}}
   \newcommand{\Ee}{\mathbb{E}}
   \newcommand{\Pp}{\mathbb{P}}
   \newcommand{\real}{\mathbb{R}}
   \newcommand{\Ybar}{\overline{Y}}
   \newcommand{\Yh}{\widehat{Y}}
   \newcommand{\Xbar}{\overline{X}}
   \newcommand{\Tr}{\text{Tr}}


   \newcommand{\model}{{\cal M}}

   \newcommand{\figvskip}{-0.7in}
   \newcommand{\fighskip}{-0.3in}
   \newcommand{\figheight}{3.5in}

   \newcommand{\Rcode}[1]{{\bf \tt #1 }}
   \newcommand{\Rtcode}[1]{{\tiny \bf \tt #1 }}
   \newcommand{\Rscode}[1]{{\small \bf \tt #1 }}

   \newcommand{\RR}{{\tt R} \;}
   \newcommand{\basename}[1]{http://stats60.stanford.edu/#1}
   \newcommand{\dataname}[1]{\basename{data/#1}}
   \newcommand{\Rname}[1]{\basename{R/#1}}

   \newcommand{\mycolor}[1]{{\color{blue} #1}}
   \newcommand{\basehref}[2]{\href{\basename{#1}}{\mycolor{#2}}}
   \newcommand{\Rhref}[2]{\href{\basename{R/#1}}{\mycolor{#2}}}
   \newcommand{\datahref}[2]{\href{\dataname{#1}}{\mycolor{#2}}}
   \newcommand{\X}{\pmb{X}}
   \newcommand{\Y}{\pmb{Y}}
   \newcommand{\be}{\pmb{varepsilon}}
   \newcommand{\logit}{\text{logit}}


   \title{Statistics 60: Introduction to Statistical Methods}
   \subtitle{Review of some key concepts, part II} 
   \author{}% {Jonathan Taylor \\
   %Department of Statistics \\
   %Stanford University
   %}


   \begin{document}

   \begin{frame}
   \titlepage
   \end{frame}

   \part{Chapters 17 \& 18: Probability histograms, normal approximation}
   \frame{\partpage}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % p = 1./2
   % x, p = conv_binom(p, 5)
   % cp = np.cumsum(p)
   % k = (cp >= 0)
   % pylab.bar(x[k],p[k], width=1, align='center', alpha=0.7)
   % 


   \begin{frame}
   \frametitle{Probability histogram of successes}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/9b704042df.pdf}}    
   \end{center}
   Tossing a fair coin 5 times, counting heads
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % X = np.random.binomial(5,0.5,1000)
   % p = np.array([(X == i).sum() for i in range(6)])/1000.
   % pylab.bar(np.arange(6),p, width=1, align='center', alpha=0.7,
   %           color='orange')
   % a = pylab.gca()
   % # a.set_ylim([0,0.6])
   % a.set_xlim([-0.6,5.6])
   % 


   \begin{frame}
   \frametitle{Empirical histogram of successes}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/7dfe81ed16.pdf}}    
   \end{center}
   Tossing a fair coin 5 times, repeating 1000 times.
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Normal approximation}

   \begin{block}
   {Example}
   \begin{description}
   \item[Q] Roulette, betting on {\color{red} 5} 100 times, 10\$ each bet starting with 100 \$.
     What are the chances we will finish with more than 200 \$?
   \item[A] We know
     \begin{itemize}
     \item $\text{average({\bf sum of draws})} = 100 \times (-0.52)\$ = -52\$ $
     \item $\text{SE({\bf sum of draws})} = \sqrt{100} \times 360 \times \sqrt{\frac{1}{38} \times \frac{37}{38}} \approx 570\$ $
     \item Finishing with more than 200\$ means the {\bf sum of draws} was greater than 100\$ .
       \item In standardized units, this is
       $$
       \frac{100-(-52)}{570} \approx 0.27
       $$
     \end{itemize}
   \end{description}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % from scipy.stats import norm
   % 
   % p = 1./2
   % n = 100
   % x, p = conv_binom(p, n)
   % cp = np.cumsum(p)
   % k = (cp >= 0)
   % XX = np.zeros(x.shape[0]+1)
   % XX[:-1] = x
   % XX[-1] = XX[-2] + 10
   % XY = XX-(XX[3]-XX[2])/2.
   % PL_density(p, XY)
   % pylab.gca().set_ylabel('$\%$ per head')
   % pylab.gca().set_xlabel('# heads')
   % 
   % mu = n * np.mean([1,0])
   % SD = np.sqrt(n) * np.std([0,1])
   % pylab.plot(XX, 100 * norm.pdf((XX-mu)/SD) / SD, linewidth=4, color='red')
   % 
   % x2 = np.linspace(40.5,100,1001)
   % y2 = 100 * norm.pdf((x2-mu)/SD) / SD
   % xf, yf = pylab.poly_between(x2, 0*x2, y2)
   % pylab.fill(xf, yf, facecolor='red', hatch='\\', alpha=0.7)
   % 
   % 
   % pylab.gca().set_xlim([35,65])
   % 


   \begin{frame}
   \frametitle{Normal approximation}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/bd2cdcdef4.pdf}}    
   \end{center}
   Observing more than 40 heads using continuity correction
   \end{frame}

   \part{Chapters 19-21: Sampling and the accuracy of percentages}
   \frame{\partpage}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Opinion polls \& percentages}

   \begin{block}
   {Model for percentages}
   \begin{itemize}
   \item An opinion poll to estimate a percentage
   is based on a sample of size $N$. We assume this is
   a {\em simple random sample}: a sample of size $N$ without replacement.

   \item The sample is from a box with one ball per population member,
   each having a 0-1 label.

   \item The estimated percentage is
   $$
   \text{\bf estimated percentage} = \frac{\text{\bf sum of $N$ draws from box}}{N}
   $$
   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import random
   % X = np.random.sample((10000,2))
   % c = ['red'] * 4800 + ['blue'] * 5200
   % s = random.sample(xrange(10000), 500)
   % for col, marker in zip(['red', 'blue'], ['>', '<']):
   %    subs = [i for i in s if c[i] == col]
   %    pylab.scatter(X[subs,0], X[subs,1], s=100, color=col, alpha=.5, marker=marker)
   % 
   % pylab.gca().set_xticks([]);    pylab.gca().set_xlim([-0.01,1.01])
   % pylab.gca().set_yticks([]);    pylab.gca().set_ylim([-0.01,1.01])
   % nred = np.array([c[ss] == 'red' for ss in s]).sum()
   % pylab.title("# Red=%d, # Blue=%d, Observed %%=%0.1f" % (nred, 500-nred, (100.*(500-nred)/500)))
   % 


   \begin{frame}
   \frametitle{Sample of 500 without replacement from a large box}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/45f1b28fba.pdf}}    
   \end{center}

   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import random
   % n = 10000
   % s = 500
   % X = np.ones(n, np.float)
   % X[:int(.48*n)] = 0.
   % data = [100 * np.array(random.sample(X, s)).sum() / s for _ in range(2000)]
   % pylab.hist(data, color='orange')
   % pylab.gca().set_xlabel('Support (%)')
   % pylab.gca().set_ylabel('Count (out of 2000)')
   % pylab.title("average=%0.1f, SD=%0.1f" % (np.mean(data), np.std(data)))
   % 


   \begin{frame}
   \frametitle{Sampling variability: (N=4800, Y=5200)}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/7857ff0bd4.pdf}}    
   \end{center}
   Drawing 500 with 2000 repeats
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Percentages}

   \begin{block}
   {Accuracy of percentages}
   \begin{itemize}
   \item Since the observed proportion is random, it has its own SE.
   \item The rule for computing the SE of a percentage
   for a simple random sample is related to SE of drawing
   from a box of 0's and 1's.
   $$
   \begin{aligned}
   \lefteqn{\text{SE(percentage from simple random sample size $N$)}} \\
   & \qquad {\color{blue} \approxeq} {\color{purple} \frac{1}{N} } \sqrt{N} \sqrt{\text{proportion 0's} \times \text{proportion 1's}} \\
   &= \frac{1}{\sqrt{N}} \sqrt{\text{proportion 0's} \times \text{proportion 1's}}
   \end{aligned}
   $$

   \item {\bf Note:} the SE does not depend on how many tickets are in the box.
   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Estimating SE when proportions unknown}

   \begin{block}
   {A second statistic}
   \begin{itemize}
   \item Given a poll, we can work out the {\em observed}
   proportion of 1's. Call this
   $$
   {\color{orange} \widehat{p}} = \text{\bf observed proportion} = \frac{\text{\# 1's in sample}}{\text{\# in sample}}
   $$
   \item We can estimate the SE of observed proportion of 1's
   $$
   \begin{aligned}
   {\color{blue} \text{SE}(\widehat{p})}& \approx {\color{purple} \frac{1}{\text{\# in sample}}}  \times  \sqrt{\text{\# in sample}} \times
   {\color{orange} \sqrt{\widehat{p} \times (1 - \widehat{p})}} \\
   & = \frac{1}{\sqrt{\text{\# in sample}}} \times
   {\color{orange} \sqrt{\widehat{p} \times (1 - \widehat{p})}} \\
   \end{aligned}
   $$

   \item We call the estimate ${\color{orange} \sqrt{\widehat{p} \times (1 - \widehat{p})}}$ of the SD of the box a {\color{orange} {\em bootstrap}} estimate.

   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Estimating percentages}

   \begin{block}
   {Normal approximation}
   \begin{itemize}
   \item Conversion to percentage points just changes the units.
   \item We can use normal approximation to approximate chances,
   as long as we standardize correctly.

   \end{itemize}
   \end{block}

   \begin{block}
   {Example}
   \begin{description}
   \item[Q] What are the chances a poll of 1000 voting age Californians
   would show an estimated approval rating for Brown less than 50\%?


   \end{description}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Confidence intervals}

   \begin{block}
   {Confidence interval for true proportion}
   \begin{itemize}
   \item Recall our model
   $$
   {\color{orange} \text{observed proportion}} = {\color{blue} \text{true proportion}} + \text{chance error}.
   $$
   \item Let's call ${\color{blue} \text{true proportion}=p}$, and recall
   ${\color{orange} \text{observed proportion}} = {\color{orange} \widehat{p}}$.
   \item The confidence interval satisfies
   $$
   \begin{aligned}
   \text{P} \left(\text{${\color{blue} p}$ between ${\color{orange} \widehat{p}} \pm \frac{2\sqrt{{\color{orange} \widehat{p}} \times (1-{\color{orange} \widehat{p}})}}{\sqrt{1000}}$}\right) &\approx 95\% \\
   \end{aligned}
   $$

   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import random
   % # need a different string to make a new version of plot
   % approval = [0] * 48000 + [1] * 52000
   % 
   % def interval(box=approval, nsample=1000):
   %     prop = np.array(random.sample(approval, nsample)).mean()
   %     SE = np.sqrt(prop * (1 - prop) / nsample)
   %     return 100 * (prop-2*SE), 100 * (prop+2*SE)
   % 
   % intervals = []
   % missed = 0
   % for i in range(200):
   %     L, U = interval()
   %     in_interval = (L <= 52) * (U >= 52)
   %     if in_interval:
   %         pylab.plot([L,U], [i,i], color='gray')
   %     else:
   %         missed += 1
   %         pylab.plot([L,U], [i,i], color='red', linewidth=10)
   % 
   % pylab.plot([52,52],[0,200], linestyle='--', linewidth=4, color='blue')
   % pylab.gca().set_yticks([])
   % pylab.title("# covering 52%%=%d, # not covering 52%%=%d" % (200-missed, missed))
   % 


   \begin{frame}
   \frametitle{An illustration of confidence intervals}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/6e8e8957f2.pdf}}    
   \end{center}
   The {\color{blue} true proportion} doesn't change.
   \end{frame}

   \part{Chapter 23 \& 24: The accuracy of averages and the Gauss model}
   \frame{\partpage}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Average of draws from a box}

   \begin{block}
   {Average of draws}
   \begin{itemize}
   \item The {\em average of the draws} is
   $$
   \text{\bf average of draws} = \frac{\text{\bf sum of draws}}{\text{{\bf $\#$ of draws}}}
   $$
   \item The expected value is the average of the box
   $$
   \text{E({\bf average of draws})} = \text{\bf average of box}
   $$

   \item The SE is
   $$
   \begin{aligned}
      \text{SE({\bf average of draws})} &= \frac{\text{SE({\bf sum of draws})}}{\text{$\#$ of draws}}      \\
      &= \frac{\text{SD({\bf box})}}{\sqrt{\text{$\#$ of draws}}}      \\
   \end{aligned}
   $$
   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % dx = 0.02
   % X, Y = np.mgrid[0.2:0.8:5j,0:1:8j]
   % X += np.random.uniform(0,1,X.shape) * dx - dx / 2
   % Y += np.random.uniform(0,1,Y.shape) * dx - dx / 2
   % ts = range(1,37) + ['0', '00']
   % success = [5]
   % tt = [('-10\$', 'yellow')] * 38
   % for r in success:
   %     tt[r] = ('+350\$', 'pink')
   % #np.random.shuffle(tt)
   % X.shape = -1; Y.shape = -1
   % g = np.array([t[1] == 'pink' for t in tt])
   % pylab.scatter(X[:38][g],Y[:38][g],s=700, c='red')
   % pylab.scatter(X[:38][~g],Y[:38][~g],s=700, c='yellow')
   % for i, t in enumerate(tt):
   %     pylab.text(X[i], Y[i], t[0], color='black', ha='center', va='center',
   %                fontsize=10)
   % 
   % pylab.gca().set_xticks([])
   % pylab.gca().set_yticks([])
   % pylab.gca().set_xlim([X.min()-0.1,X.max()+0.1])
   % pylab.gca().set_ylim([Y.min()-0.1,Y.max()+0.2])
   % 


   \begin{frame}
   \frametitle{Example of a box model}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/ee2884116d.pdf}}    
   \end{center}
   Betting 10\$ on {\color{red} 5}: win 350\$ with probability 1/38
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Estimating SE when content of box is unknown}

   \begin{block}
   {Accuracy of averages second statistic}
   \begin{itemize}
   \item Given a sample ${\color{orange}[X_1, \dots, X_n]}$ of $n$ draws, we can compute the {\em sample mean}
   $$
   {\color{orange} \bar{X}}  = \frac{{\color{orange} \text{\bf sum of draws}}}{{\color{blue} \text{$\#$ of draws}}}  = \frac{{\color{orange} \sum_{i=1}^n X_i}}{{\color{blue} n}}
   $$
   \item We use {\color{orange} plug-in / bootstrap} estimate
   $$
   {\color{orange}\widehat{ \text{SE}(\bar{X})}} = \frac{{\color{orange}\text{SD($[X_1, \dots, X_n]$)}}}{{\color{blue}\sqrt{ \text{$\#$ of draws}}}} =  \frac{{\color{orange} \sqrt{\frac{1}{n}\sum_{i=1}^n (X_i - \bar{X})^2}}}{\color{blue} \sqrt{n}}
   $$

   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Estimating {\color{blue} average({\bf box})}}

   \begin{block}
   {Normal approximation}
   \begin{itemize}
   \item Conversion to average just changes the units.
   \item We can use normal approximation to approximate chances,
   as long as we standardize correctly.
   \item For example, a 90\% confidence interval can be found using
   $$
   \begin{aligned}
   \text{P} \left(\text{${\color{blue} \mu}$ between ${\color{orange} \bar{X} \pm 1.65 \times \; \text{SD}([X_1, \dots, X_{100}]) / \sqrt{100}}$}\right) &\approx 90\% \\
   \end{aligned}
   $$

   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Gauss model}

   \begin{block}
     {Gauss model}
     \begin{itemize}
     \item The Gauss model assume that each measurement has the form
     $$
     {\color{orange} \text{measurement}} = {\color{blue} \text{true value}} + {\color{orange} \text{chance error}}
     $$
     \item When the Gauss model holds, taking a measurement corresponds
     to drawing from an {\color{orange} error box} and adding
     a {\color{blue} true value}.

     \item If the measurement is biased, the Gauss model is
     $$
     {\color{orange} \text{measurement}} = {\color{blue} \text{true value}} + {\color{purple} \text{bias}} + {\color{orange} \text{chance error}}
     $$

     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Gauss model}

   \begin{block}
     {No box, no inference}
     \begin{itemize}
     \item If you can't accurately describe your chance process as
     drawing from a box
     you can't use these formulae for SE because they were all
     based on drawing from a box.

     \end{itemize}
   \end{block}
   \end{frame}

   \part{Chapter 26-28: Tests of Significance}
   \frame{\partpage}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Testing hypotheses}

   \begin{block}
   {Online gaming}
   \begin{itemize}
   \item If you play online poker or roulette, how do you know it's fair?

   \item I placed 10 bets on {\color{red} RED} on
   \href{http://www.roulette4fun.com/roulette-games/classic-roulette}{http://www.roulette4fun.com/roulette-games/classic-roulette}.

   \item These are the results: [0,0,1,0,1,0,0,1,0,1].

   \item If the roulette wheel is fair,
   I would expect to see $10 \times 18/ 38=4.7$ successes, give or take
   $\sqrt{10} \times \sqrt{18/38 \times 20/38}=1.4$.

   \item In standardized units, my observed 4 successes converts to
   $$
   \frac{{\color{orange} 4} - {\color{blue} 4.7}}{{\color{blue} 1.4}} = {\color{orange} -0.5}
   $$

   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import random
   % X = np.mgrid[0:1:10j,0:1:5j].reshape((2,50)) + np.random.sample((2,50)) * 0.05
   % X = X.T
   % sample = [random.randint(-15,0) for _  in range(50)]
   % for i in range(50):
   %     pylab.text(X[i,0], X[i,1], '%d' % sample[i])
   % 
   %     pylab.gca().set_xticks([]);    pylab.gca().set_xlim([-0.1,1.1])
   %     pylab.gca().set_yticks([]);    pylab.gca().set_ylim([-0.1,1.1])
   % pylab.title("average(sample)=-7.4, SD(sample)=4.8") # % (np.mean(sample), np.std(sample)))
   % 


   \begin{frame}
   \frametitle{Sample of blood pressures}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/3e7e808490.pdf}}    
   \end{center}
   Sample of 50
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Testing hypotheses}

   \begin{block}
   {Setting up the test}
   \begin{itemize}

   \item We could set this up as drawing from a box of {\em differences
   in blood pressure}.

   \item The {\em null hypothesis}, $H_0$ is: ``the average difference is zero.''

   \item The {\em alternative hypothesis}, $H_a$, is: ``the average difference is less than zero.''

   \item We test the null with observed data by estimating
    the average difference and converting to standardized units.
   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Testing hypotheses}

   \begin{block}
   {Evaluating  the test}
   \begin{itemize}

   \item Our observed average is ${-\color{orange} 7.4}$. We estimate its SE
   to be ${\color{orange} 4.8 / \sqrt{50}=0.7}$.

    \item In standardized units, our observed average converts to
    $$
    \frac{{\color{orange}-7.4} - {\color{blue} 0}}{\color{orange} 0.7} \approx - 10
    $$

   \item The {\color{orange} $P$-value} is 0: there is virtually no chance
   a standard normal would ever be so small. We reject the null hypothesis $H_0$
   and conclude $H_a$: ``the average difference is negative.''


   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Testing hypotheses}

   \begin{block}
   {Rejection rule}
   \begin{itemize}

   \item Knowing the null and alternative hypotheses and the size of the test,
   we can define a {\em \color{blue} rejection rule}.

   \item For example, if the size is 5\%, and
   $$
   \begin{aligned}
     H_0 &= \text{average difference is 0 mm Hg} \\
     H_a &= \text{average difference is negative} \\
   \end{aligned}
   $$
   \item Then, we reject $H_0$ if our $z$ statistic is
   less than {\color{blue} -1.65}.

   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import pylab, numpy as np
   % x = np.linspace(-4,4,101)
   % y = np.exp(-x**2/2) / np.sqrt(2*np.pi)
   % x2 = np.linspace(-4,-1.65,101)
   % y2 = np.exp(-x2**2/2) / np.sqrt(2*np.pi)
   % pylab.plot(x,y*100, linewidth=2)
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='red', hatch='\\', alpha=0.5)
   % pylab.gca().set_xlabel('standardized units')
   % pylab.gca().set_ylabel('% per standardized unit')
   % #pylab.gca().set_xlim([-2,4])
   % #pylab.gca().set_yticks([])
   % 


   \begin{frame}
   \frametitle{One sided test}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/73222db9d8.pdf}}    
   \end{center}
   {\color{blue} 5\% rejection rule} when alternative is negative \dots
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import pylab, numpy as np
   % x = np.linspace(-4,4,101)
   % y = np.exp(-x**2/2) / np.sqrt(2*np.pi)
   % 
   % x2 = np.linspace(2,4,101)
   % y2 = np.exp(-x2**2/2) / np.sqrt(2*np.pi)
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='red', hatch='\\', alpha=0.5)
   % 
   % 
   % x2 = np.linspace(-4,-2,101)
   % y2 = np.exp(-x2**2/2) / np.sqrt(2*np.pi)
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='red', hatch='\\', alpha=0.5)
   % 
   % pylab.plot(x,y*100, linewidth=2)
   % pylab.gca().set_xlabel('standardized units')
   % pylab.gca().set_ylabel('% per standardized unit')
   % #pylab.gca().set_xlim([-2,4])
   % #pylab.gca().set_yticks([])
   % 


   \begin{frame}
   \frametitle{Two sided test}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/bbd6d849ef.pdf}}    
   \end{center}
   {\color{blue} 5\% rejection rule} when alternative is positive or negative \dots
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import pylab, numpy as np
   % x = np.linspace(-4,4,101)
   % y = np.exp(-x**2/2) / np.sqrt(2*np.pi)
   % x2 = np.linspace(1.65,4,101)
   % y2 = np.exp(-x2**2/2) / np.sqrt(2*np.pi)
   % pylab.plot(x,y*100, linewidth=2)
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='red', hatch='\\', alpha=0.5)
   % pylab.gca().set_xlabel('standardized units')
   % pylab.gca().set_ylabel('% per standardized unit')
   % #pylab.gca().set_xlim([-2,4])
   % #pylab.gca().set_yticks([])
   % 


   \begin{frame}
   \frametitle{One sided test}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/87f9fdb9ee.pdf}}    
   \end{center}
   {\color{blue} 5\% rejection rule} when alternative is positive \dots
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Student's $T$}

   \begin{block}
   {Tests for small samples}
   \begin{itemize}

   \item Suppose the Gauss model holds
     $$
     {\color{orange} \text{measurement}} = {\color{blue} \text{true value}} + {\color{orange} \text{chance error}}
     $$
   \item {\bf And, the histogram of the error box is not too different
   from a normal probability histogram or curve}

    \item The $T$ statistic replaces the SD of the list with SD$^+$ of
   the list, but uses a different curve based on
     {\em degrees of freedom}
   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Student's $T$ table: A-105}

   \begin{block}
   {Sample rows of the table look like}
   \begin{tabular}{ccccccc}
   {\small degrees of freedom} & 25\% & 10\% & 5\% & 2.5\% & 1\% & 0.5 \% \\ \hline

   4 & 0.74 & 1.53 & 2.13 & 2.78 & 3.75 & 4.60 \\
   20 & 0.69 & 1.33 & 1.72 & 2.09 & 2.53 & 2.85 \\
   \end{tabular}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import pylab, numpy as np
   % import scipy.stats
   % 
   % df = 4
   % 
   % # The t region
   % 
   % x = np.linspace(-4,4,101)
   % pylab.plot(x,scipy.stats.t.pdf(x, df)*100, linewidth=2, label=r'$T$, df=%d, 10%%' % df, color='black')
   % x2 = np.linspace(scipy.stats.t.isf(0.10,df),4, 101)
   % y2 = scipy.stats.t.pdf(x2, df)
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='gray', hatch='\\', alpha=0.5)
   % pylab.text(scipy.stats.t.isf(0.10,df), -3, r'$t$', size=20)
   % # pylab.gca().set_xlabel('standardized units')
   % # pylab.gca().set_ylabel('% per standardized unit')
   % # pylab.legend()
   % pylab.gca().set_yticks([])
   % # pylab.gca().set_xticks([])
   % pylab.gca().set_xlim([-3,3])
   % 


   \begin{frame}
   \frametitle{Student's $T$}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/76434ce364.pdf}}    
   \end{center}
   A-105, for $df=4$, the 10\% one-sided cutoff is 1.53
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Comparing two samples}

   \begin{block}
   {NAEP reading test}
   \begin{itemize}
   \item In 1990, sample average was 290.

   \item In 2004, sample average was 285.

   \item One box for 1990, average(1990 sample) = 290, SD(2004 sample) = 37.

   \item A second box for 2004, average(2004 sample) = 285, SD(2004 sample) = 40.

   \item So,
   $$
   \begin{aligned}
   \text{SE(average(1990 sample))} &\approx 37 / \sqrt{1000} \\
    &\approx 1.2\\
   \text{SE(average(2004 sample))} &\approx 40 / \sqrt{1000} \\
   &\approx 1.3\\
   \end{aligned}
   $$

   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Comparing two samples}

   \begin{block}
   {SE of a difference}
   \begin{itemize}

   \item So, the denominator should be
   $$
   {\color{blue} \text{SE}}({\color{orange} \text{average(2004 sample) -
   average(1990 sample)}}).
   $$

   \item The SE of the difference of two {\bf independent}
   quantities can be found from the individual SEs.

   \item The rule is
   $$
   \begin{aligned}
   \lefteqn{{\color{blue} \text{SE}}({\color{orange}
   \text{average(2004 sample) -
   average(1990 sample)}})} \\
   & \qquad \quad = \sqrt{{\color{blue}\text{SE}}({\color{orange} \text{1990 sample}})^2 + {\color{blue}\text{SE}}({\color{orange} \text{2004 sample}})^2}.
   \end{aligned}
   $$

   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Comparing two samples}

   \begin{block}
   {Example}
   \begin{itemize}
   \item In 1999, 13\% of the 17 year-old students had taken calculus
   compared to 17\% in 2004 according to the NAEP samples.
   Is the difference real or chance variation?

   \item This question asks us to compare two proportions. We can take
   the null hypothesis to be ``the proportion of 17 year olds who took
   calculus in 1999 is equal to (or greater than or equal to) the
   proportion who took calculus in 2004.''

   \item The alternative is ``the proportion of 17 year olds
   who took calculus in 1999 is less than the proportion who took calculus
   in 2004.''
   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Randomized experiments}

   \begin{block}
   {Randomized experiments}
   \begin{itemize}
   \item This {\em two-sample $z$-test} can also be used
   for randomized controlled experiments.

   \item Example:  200 subjects are split randomly into treatment
   and placebo in a study on vitamin C on the number of colds.

   \item In the treatment group average(treatment group)=2.3,
   SD(treatment group) = 3.1.

   \item In the placebo group average(placebo group)=2.6,
   SD(placebo group) = 2.9.

   \item Is there a difference in the number of colds in treatment
   vs. placebo group?


   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Randomized experiments}

   \begin{block}
   {Example (continued)}
   \begin{itemize}
   \item Naively applying the two sample
   $z$-test to this situation, yields
   $$
   z = \frac{(2.3 - 2.6) - 0}{\sqrt{\left(\frac{3.1}{\sqrt{100}}\right)^2 + \left(\frac{2.9}{\sqrt{100}}\right)^2}} = \frac{-0.3}{0.42} \approx -0.7.
   $$


   \item If we had taken a one-sided alternative, this would be a $P$-value of about 25\%.

   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import numpy as np, pylab
   % import random
   % 
   % ## sample2 = [np.random.randint(0,6) for _  in range(200)]
   % ## sample = [np.random.randint(0,6) for _  in range(200)]
   % ## X = np.array([(s1,s2) for s1, s2 in zip(sample, sample2)], np.dtype([('sample1', np.int), ('sample2', np.int)]))
   % ## treatment = random.sample(range(200), 100)
   % ## treatment_bool = np.zeros(X.shape, np.bool)
   % ## for i in treatment:
   % ##     treatment_bool[i] = True
   % ## X = pylab.rec_append_fields(X, 'treatment', treatment_bool)
   % ## pylab.rec2csv(X, '%s/twosample.csv' % datadir)
   % 
   % import random
   % X = np.mgrid[0:10:10j,0:20:20j].reshape((2,200))   + np.random.sample((2,200)) * 0.05
   % X = X.T
   % sample = pylab.csv2rec('%s/twosample.csv' % datadir)
   % 
   % treatment = sample['treatment'].astype(np.bool)
   % treatment_sample = sample[treatment]['sample1']
   % placebo_sample = sample[~treatment]['sample2']
   % 
   % 
   % for i in range(200):
   %    pylab.fill_between([X[i,0]-.4,X[i,0]], [X[i,1]-.4,X[i,1]-.4], [X[i,1]+.3,X[i,1]+.3], facecolor='green', alpha=0.3)
   %    pylab.fill_between([X[i,0],X[i,0]+.4], [X[i,1]-.4,X[i,1]-.4], [X[i,1]+.3,X[i,1]+.3], facecolor='red', alpha=0.3)
   %    pylab.text(X[i,0]-0.2, X[i,1], '%d' % sample['sample1'][i], ha='center', va='center', size=10)
   %    pylab.text(X[i,0]+0.2, X[i,1], '%d' % sample['sample2'][i], ha='center', va='center', size=10)
   %    pylab.gca().set_xticks([]);    pylab.gca().set_xlim([-1,11])
   %    pylab.gca().set_yticks([]);    pylab.gca().set_ylim([-1,21])
   % 


   \begin{frame}
   \frametitle{Box model (hypothetical data)}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/5223837e44.pdf}}    
   \end{center}
   The complete data (unobserved)
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import numpy as np, pylab
   % import random
   % 
   % ## sample2 = [np.random.randint(0,6) for _  in range(200)]
   % ## sample = [np.random.randint(0,6) for _  in range(200)]
   % ## X = np.array([(s1,s2) for s1, s2 in zip(sample, sample2)], np.dtype([('sample1', np.int), ('sample2', np.int)]))
   % ## treatment = random.sample(range(200), 100)
   % ## treatment_bool = np.zeros(X.shape, np.bool)
   % ## for i in treatment:
   % ##     treatment_bool[i] = True
   % ## X = pylab.rec_append_fields(X, 'treatment', treatment_bool)
   % ## pylab.rec2csv(X, '%s/twosample.csv' % datadir)
   % 
   % import random
   % X = np.mgrid[0:10:10j,0:20:20j].reshape((2,200))   + np.random.sample((2,200)) * 0.05
   % X = X.T
   % sample = pylab.csv2rec('%s/twosample.csv' % datadir)
   % 
   % treatment = sample['treatment'].astype(np.bool)
   % treatment_sample = sample[treatment]['sample1']
   % placebo_sample = sample[~treatment]['sample2']
   % 
   % 
   % for i in range(200):
   %    pylab.fill_between([X[i,0]-.4,X[i,0]], [X[i,1]-.4,X[i,1]-.4], [X[i,1]+.3,X[i,1]+.3], facecolor='green', alpha=0.3)
   %    pylab.fill_between([X[i,0],X[i,0]+.4], [X[i,1]-.4,X[i,1]-.4], [X[i,1]+.3,X[i,1]+.3], facecolor='red', alpha=0.3)
   %    if treatment[i]:
   %        pylab.text(X[i,0]-0.2, X[i,1], '%d' % sample['sample1'][i], ha='center', va='center', size=10)
   %    elif not treatment[i]:
   %        pylab.text(X[i,0]+0.2, X[i,1], '%d' % sample['sample2'][i], ha='center', va='center', size=10)
   % pylab.gca().set_xticks([]);    pylab.gca().set_xlim([-1,11])
   % pylab.gca().set_yticks([]);    pylab.gca().set_ylim([-1,21])
   % 


   \begin{frame}
   \frametitle{Box model (hypothetical data)}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/e6d8032720.pdf}}    
   \end{center}
   The entire sample (observed).
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Randomized experiments}

   \begin{block}
   {Binary responses}
   \begin{itemize}
   \item The randomization model is not applicable only to
   quantitative things like the number of colds. The tickets
   can have 0-1 values.

   \item Suppose the experiment tests an experimental cancer treatment
   and our outcome is whether or not the subject is remission free 5 years
   after treatment.

   \item Each subject has a {\color{green} 1 or 0} for their
   outcome if they are treated, and a {\color{red} 1 or 0} for their
   outcome if they receive placebo (or, more likely, standard of care).

   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % ## import random
   % ## sample2 = np.random.binomial(1, 0.6, (200,))
   % ## sample = np.random.binomial(1, 0.8, (200,))
   % ## X = np.array([(s1,s2) for s1, s2 in zip(sample, sample2)], np.dtype([('sample1', np.int), ('sample2', np.int)]))
   % ## treatment = random.sample(range(200), 100)
   % ## treatment_bool = np.zeros(X.shape, np.bool)
   % ## for i in treatment:
   % ##     treatment_bool[i] = True
   % ## X = pylab.rec_append_fields(X, 'treatment', treatment_bool)
   % ## pylab.rec2csv(X, 'data/twosample_binary.csv')
   % 
   % X = np.mgrid[0:10:10j,0:20:20j].reshape((2,200))   + np.random.sample((2,200)) * 0.05
   % X = X.T
   % sample = pylab.csv2rec('%s/twosample_binary.csv' % datadir)
   % 
   % treatment = sample['treatment'].astype(np.bool)
   % treatment_sample = sample[treatment]['sample1']
   % placebo_sample = sample[~treatment]['sample2']
   % 
   % 
   % for i in range(200):
   %    pylab.fill_between([X[i,0]-.4,X[i,0]], [X[i,1]-.4,X[i,1]-.4], [X[i,1]+.3,X[i,1]+.3], facecolor='green', alpha=0.3)
   %    pylab.fill_between([X[i,0],X[i,0]+.4], [X[i,1]-.4,X[i,1]-.4], [X[i,1]+.3,X[i,1]+.3], facecolor='red', alpha=0.3)
   %    pylab.text(X[i,0]-0.2, X[i,1], '%d' % sample['sample1'][i], ha='center', va='center', size=10)
   %    pylab.text(X[i,0]+0.2, X[i,1], '%d' % sample['sample2'][i], ha='center', va='center', size=10)
   %    pylab.gca().set_xticks([]);    pylab.gca().set_xlim([-1,11])
   %    pylab.gca().set_yticks([]);    pylab.gca().set_ylim([-1,21])
   % 


   \begin{frame}
   \frametitle{Box model (for binary outcome)}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/c4200da009.pdf}}    
   \end{center}

   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % # import random
   % ## sample2 = np.random.binomial(1, 0.6, (200,))
   % ## sample = np.random.binomial(1, 0.8, (200,))
   % ## X = np.array([(s1,s2) for s1, s2 in zip(sample, sample2)], np.dtype([('sample1', np.int), ('sample2', np.int)]))
   % ## treatment = random.sample(range(200), 100)
   % ## treatment_bool = np.zeros(X.shape, np.bool)
   % ## for i in treatment:
   % ##     treatment_bool[i] = True
   % ## X = pylab.rec_append_fields(X, 'treatment', treatment_bool)
   % ## pylab.rec2csv(X, 'data/twosample_binary.csv')
   % 
   % X = np.mgrid[0:10:10j,0:20:20j].reshape((2,200))   + np.random.sample((2,200)) * 0.05
   % X = X.T
   % sample = pylab.csv2rec('%s/twosample_binary.csv' % datadir)
   % 
   % treatment = sample['treatment'].astype(np.bool)
   % treatment_sample = sample[treatment]['sample1']
   % placebo_sample = sample[~treatment]['sample2']
   % 
   % 
   % for i in range(200):
   %    pylab.fill_between([X[i,0]-.4,X[i,0]], [X[i,1]-.4,X[i,1]-.4], [X[i,1]+.3,X[i,1]+.3], facecolor='green', alpha=0.3)
   %    pylab.fill_between([X[i,0],X[i,0]+.4], [X[i,1]-.4,X[i,1]-.4], [X[i,1]+.3,X[i,1]+.3], facecolor='red', alpha=0.3)
   %    if treatment[i]:
   %        pylab.text(X[i,0]-0.2, X[i,1], '%d' % sample['sample1'][i], ha='center', va='center', size=10)
   %    elif not treatment[i]:
   %        pylab.text(X[i,0]+0.2, X[i,1], '%d' % sample['sample2'][i], ha='center', va='center', size=10)
   % pylab.gca().set_xticks([]);    pylab.gca().set_xlim([-1,11])
   % pylab.gca().set_yticks([]);    pylab.gca().set_ylim([-1,21])
   % 


   \begin{frame}
   \frametitle{Box model (for binary outcome)}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/a6f3e6d63b.pdf}}    
   \end{center}
   The entire sample (observed).
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{$\chi^2$ goodness of fit tests}

   \begin{block}
   {Is the die fair?}
   \begin{itemize}

     \begin{tabular}{c|c|c|p{1in}}
       {\small Value} & {\small Observed Count} & {\small Expected Count} & {\small Observed - Expected} \\ \hline
       1 & 4 & 10 & -6  \\
       2 & 6 & 10 & -4 \\
       3 & 17 & 10 & 7 \\
       4 & 16 & 10 & 6 \\
       5 & 8 & 10 & -2 \\
       6 & 9 & 10 & -1 \\ \hline
       Total & 60 & 60 & 0 \\
     \end{tabular}

     \item It seems there are too many 3's, and too few 1's...

   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Goodness of fit tests}

   \begin{block}
   {$\chi^2$ statistic}
   \begin{itemize}
   \item To get an overall tests, we combine the rows into {\em Pearson's $\chi^2$}
     $$
     \begin{aligned}
     {\color{orange} \chi^2} &= {\color{orange} \text{sum} \left(\frac{\text{(Observed - Expected)$^2$}}{\text{Expected}}\right)} = {\color{orange} \sum_{i=1}^6 \frac{(O_i - E_i)^2}{E_i}}
     \end{aligned}
     $$

     \item In the die example,
       $$
       \begin{aligned}
       {\color{orange} \chi^2} &= {\color{orange} \frac{(-6)^2}{10} + \frac{(-4)^2}{10} + \frac{7^2}{10} + \frac{6^2}{10} + \frac{(-2)^2}{10} + \frac{(-1)^2}{10}} \\
       &= {\color{orange} \frac{142}{10}} \\
       &= {\color{orange} 14.2}
       \end{aligned}
       $$

   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import pylab, numpy as np
   % import scipy.stats
   % x = np.linspace(0,20,101)
   % y = scipy.stats.chi2.pdf(x, 5)
   % x2 = np.linspace(14.2,20,101)
   % y2 = scipy.stats.chi2.pdf(x2, 5)
   % pylab.plot(x,y*100, linewidth=2)
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='red', hatch='\\', alpha=0.5)
   % pylab.gca().set_xlabel('standardized units')
   % pylab.gca().set_ylabel('% per standardized unit')
   % 


   \begin{frame}
   \frametitle{What are the chances?}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/2ca98aef04.pdf}}    
   \end{center}
   The $\chi^2_5$ probability histogram, the area is 1.4\%
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{$\chi^2$ curves}

   \begin{block}
   {Using the $\chi^2$ test}

   \begin{itemize}
   \item A general rule of thumb: every expected value should be 5 or more
   for the $\chi^2$ curve to approximate the probability
   histogram of the ${\color{orange} \chi^2}$ statistic.

   \item Would not apply to 100 draws from
     $$
       \fbox{ \fbox{1} \ \fbox{2} \  \fbox{3} \ \ 96 \fbox{4}'s}
     $$


   \end{itemize}
   \end{block}

   \begin{block}
     {Difference between $\chi^2$ test and $z$ test}
     \begin{itemize}
     \item The $z$ test is a statement about the average of the box.
     \item The $\chi^2$ is a test whether the  observed data follow the
     box model.
     \item If there are only two values in the box, then the
     $\chi^2$ test is identical to the (two-sided) $z$ test.
     \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{$\chi^2$ table: A-106}

   \begin{block}
   {Sample rows of the table look like}
    \begin{tabular}{cccccccccc}
    {\tiny degrees of freedom} & \dots & {\tiny 70\%} & {\tiny 50\%} & {\tiny 30\%} & {\tiny 10\%} & {\tiny 5 \%} & {\tiny 1 \%} \\ \hline
   5 & \dots & 3.00 & 4.35 & 6.06 & 9.24 & 11.07 & 15.09 \\
    \end{tabular}
    \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import pylab, numpy as np
   % import scipy.stats
   % df = 5
   % x = np.linspace(0,20,501)
   % y = scipy.stats.chi2.pdf(x, df)
   % q = scipy.stats.chi2.isf(0.05, df)
   % x2 = np.linspace(q,20,501)
   % y2 = scipy.stats.chi2.pdf(x2, df)
   % pylab.plot(x,y*100, linewidth=2, color='black')
   % xf, yf = pylab.poly_between(x2, 0*x2, y2*100)
   % pylab.fill(xf, yf, facecolor='gray', hatch='\\', alpha=0.5)
   % #pylab.gca().set_xlabel('standardized units')
   % #pylab.gca().set_ylabel('% per standardized unit')
   % #pylab.gca().set_xticks([])
   % pylab.gca().set_yticks([])
   % pylab.gca().set_xlim([0,15])
   % 
   % pylab.text(q, -1.5, r'$\chi^2$', size=20)
   % 


   \begin{frame}
   \frametitle{$\chi^2$ curves}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/45e71a8c22.pdf}}    
   \end{center}
   The 5\% rejection rule for $\chi^2_5$: reject if ${\color{orange} \chi^2} > 11.07$
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} 

   \end{frame}

   \end{document}
