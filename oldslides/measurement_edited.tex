   \documentclass[handout]{beamer}



   \mode<presentation>
   {
     \usetheme{PaloAlto}
   \setbeamertemplate{footline}[page number]

     \setbeamercolor{sidebar}{bg=white, fg=black}
     \setbeamercolor{frametitle}{bg=white, fg=black}
     % or ...
     \setbeamercolor{logo}{bg=white}
     \setbeamercolor{block body}{parent=normal text,bg=white}
     \setbeamercolor{author in sidebar}{fg=black}
     \setbeamercolor{title in sidebar}{fg=black}


     \setbeamercolor*{block title}{use=structure,fg=structure.fg,bg=structure.fg!20!bg}
     \setbeamercolor*{block title alerted}{use=alerted text,fg=alerted text.fg,bg=alerted text.fg!20!bg}
     \setbeamercolor*{block title example}{use=example text,fg=example text.fg,bg=example text.fg!20!bg}


     \setbeamercolor{block body}{parent=normal text,use=block title,bg=block title.bg!50!bg}
     \setbeamercolor{block body alerted}{parent=normal text,use=block title alerted,bg=block title alerted.bg!50!bg}
     \setbeamercolor{block body example}{parent=normal text,use=block title example,bg=block title example.bg!50!bg}

     % or ...

     \setbeamercovered{transparent}
     % or whatever (possibly just delete it)
     \logo{\resizebox{!}{1.5cm}{\href{\basename{R}}{\includegraphics{image}}}}
   }

   \mode<handout>
   {
     \usetheme{PaloAlto}
     \usecolortheme{default}
     \setbeamercolor{sidebar}{bg=white, fg=black}
     \setbeamercolor{frametitle}{bg=white, fg=black}
     % or ...
     \setbeamercolor{logo}{bg=white}
     \setbeamercolor{block body}{parent=normal text,bg=white}
     \setbeamercolor{author in sidebar}{fg=black}
     \setbeamercolor{title in sidebar}{fg=black}
     \setbeamercovered{transparent}
     % or whatever (possibly just delete it)
     \logo{}
   }

   \usepackage{epsdice}
   \usepackage[latin1]{inputenc}
   \usepackage{graphics}
   \usepackage{amsmath,eepic,epic}

   \newcommand{\figslide}[3]{
   \begin{frame}
   \frametitle{#1}
     \begin{center}
     \resizebox{!}{2.7in}{\includegraphics{#2}}    
     \end{center}
   {#3}
   \end{frame}
   }

   \newcommand{\fighslide}[4]{
   \begin{frame}
   \frametitle{#1}
     \begin{center}
     \resizebox{!}{#4}{\includegraphics{#2}}    
     \end{center}
   {#3}
   \end{frame}
   }

   \newcommand{\figwref}[1]{
   \href{#1}{\tiny \tt #1}}

   \newcommand{\B}[1]{\beta_{#1}}
   \newcommand{\Bh}[1]{\widehat{\beta}_{#1}}
   \newcommand{\V}{\text{Var}}
   \newcommand{\Cov}{\text{Cov}}
   \newcommand{\Vh}{\widehat{\V}}
   \newcommand{\s}{\sigma}
   \newcommand{\sh}{\widehat{\sigma}}

   \newcommand{\argmax}[1]{\mathop{\text{argmax}}_{#1}}
   \newcommand{\argmin}[1]{\mathop{\text{argmin}}_{#1}}
   \newcommand{\Ee}{\mathbb{E}}
   \newcommand{\Pp}{\mathbb{P}}
   \newcommand{\real}{\mathbb{R}}
   \newcommand{\Ybar}{\overline{Y}}
   \newcommand{\Yh}{\widehat{Y}}
   \newcommand{\Xbar}{\overline{X}}
   \newcommand{\Tr}{\text{Tr}}


   \newcommand{\model}{{\cal M}}

   \newcommand{\figvskip}{-0.7in}
   \newcommand{\fighskip}{-0.3in}
   \newcommand{\figheight}{3.5in}

   \newcommand{\Rcode}[1]{{\bf \tt #1 }}
   \newcommand{\Rtcode}[1]{{\tiny \bf \tt #1 }}
   \newcommand{\Rscode}[1]{{\small \bf \tt #1 }}

   \newcommand{\RR}{{\tt R} \;}
   \newcommand{\basename}[1]{http://stats60.stanford.edu/#1}
   \newcommand{\dataname}[1]{\basename{data/#1}}
   \newcommand{\Rname}[1]{\basename{R/#1}}

   \newcommand{\mycolor}[1]{{\color{blue} #1}}
   \newcommand{\basehref}[2]{\href{\basename{#1}}{\mycolor{#2}}}
   \newcommand{\Rhref}[2]{\href{\basename{R/#1}}{\mycolor{#2}}}
   \newcommand{\datahref}[2]{\href{\dataname{#1}}{\mycolor{#2}}}
   \newcommand{\X}{\pmb{X}}
   \newcommand{\Y}{\pmb{Y}}
   \newcommand{\be}{\pmb{varepsilon}}
   \newcommand{\logit}{\text{logit}}


   \title{Statistics 60: Introduction to Statistical Methods}
   \subtitle{Chapter 6: Measurement Error} 
   \author{}% {Jonathan Taylor \\
   %Department of Statistics \\
   %Stanford University
   %}


   \begin{document}

   \begin{frame}
   \titlepage
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Measurements}

   \begin{block}
   {Measurements and Data}
   \begin{itemize}
   \item We've talked about summaries of a list of numbers so far...
   \item All such numbers come from some {\em measurement procedure}.
   \item For example, Stanford frosh SAT scores were {\em measured}
   when you had your best SAT score.
   \item Book uses the example of $K_{20}$ the US national
   prototype kilogram.
   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Measurement}

   \begin{block}
   {Measurement error (excerpt from book)}
   {\em No matter how carefully it was made, a measurement could have
   come out a bit differently.}

   \end{block}

   \begin{block}
   {By how much?}
   The best way to find out is to replicate the measurement.

   The SD of the replicates estimates the likely
   size of the chance error in a single measurement.

   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Measurement}

   \begin{block}
   {Measurement model}

   $$
   \text{individual measurement} = \text{exact value} + \text{chance error}
   $$
   \end{block}

   \begin{block}
   {$\Sigma$ notation}

   \begin{itemize}
   \item Call the individual measurement $M$
   \item the exact value $\mu$
   \item the chance error $\epsilon$
   \end{itemize}

   $$
   M = \mu + \epsilon
   $$
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Measurement}

   \begin{block}
   {Several measurements}

   Produces a list with $n$ entries
   $$
   \text{individual measurement}_i = \text{exact value} + \text{chance error}_i
   $$
   \end{block}

   \begin{block}
   {$\Sigma$ notation}

   Call our list of measurements $X=[X_1, \dots, X_n]$.
   Then,
   $$
   X_i = \mu + \epsilon_i
   $$
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Measurement}

   \begin{block}
   {Histogram of the measurements}
   \begin{itemize}
   \item Our measurement model says that the only thing
   changing between measurements is the chance error.
   \item The histogram of the measurements will be the histogram
   of the {\em chance error}, shifted to the {\em exact value}.
   \item In standard units, the histogram of the {\em measurements}
   will look like
   the histogram of the {\em chance error} in standard units.
   \item If the normal curve fits the histogram of the {\em chance error} well,
   it will fit the histogram of the {\em measurements} well as well.
   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Measurement}

   \begin{block}
   {Example: Weighing an apple}
   \begin{itemize}
   \item Suppose we have an apple that weights exactly 8 ounces.
   \item Experiment: weigh the apple 100 different times.
   \item If we know the exact weight of the apple is 8 ounces,
   we can find the chance errors.
   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import matplotlib.mlab as ML
   % data = ML.csv2rec('%s/apples_oranges.csv' % datadir)['apple_errors'] + 8
   % pylab.hist(data, bins=30, facecolor='blue', alpha=0.5)
   % pylab.gca().set_yticks([])
   % pylab.gca().set_xlabel('Weight of apple (ounces)')
   % pylab.gca().set_title('Mean: %0.1f, SD: %0.1f' % (data.mean(), data.std()))
   % 


   \begin{frame}
   \frametitle{Histogram of apples}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/aa1a21a500.pdf}}    
   \end{center}

   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import matplotlib.mlab as ML
   % data = ML.csv2rec('%s/apples_oranges.csv' % datadir)['apple_errors']
   % pylab.hist(data, bins=30, facecolor='blue', alpha=0.5)
   % pylab.gca().set_yticks([])
   % pylab.gca().set_xlabel('Chance error (ounces)')
   % pylab.gca().set_title('Mean: %0.1f, SD: %0.1f' % (data.mean(), data.std()))
   % 


   \begin{frame}
   \frametitle{Histogram of chance error}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/fe4beac289.pdf}}    
   \end{center}

   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Measurement}

   \begin{block}
   {Outliers}
   \begin{itemize}
   \item Not all individual measurements fit the
   normal curve.
   \item This could be because the histogram of
   measurements {\em shouldn't} fit the normal curve exactly \dots
   \item Or, an error was made in some of the measurements \dots
   \item Usually impossible to tell which \dots
   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Bias: systematic error}

   \begin{block}
   {Conceptual definition (excerpt from book)}
   {\em Bias affects all measurements the same way, pushing them
   in the same direction. Chance errors change from measurement
   to measurement, sometimes up and sometimes down.}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Measurement}

   \begin{block}
   {Measurement model}

   $$
   \text{individual measurement} = \text{exact value} + \text{bias} + \text{chance error}
   $$
   \end{block}

   \begin{block}
   {$\Sigma$ notation}

   \begin{itemize}
   \item Call the bias $B$
   \end{itemize}

   $$
   M = \mu + B + \epsilon
   $$
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Measurement  with bias}

   \begin{block}
   {Several measurements}

   Produces a list with $n$ entries
   $$
   \text{individual measurement}_i = \text{exact value} + \text{bias} + \text{chance error}_i
   $$
   \end{block}

   \begin{block}
   {$\Sigma$ notation}

   Call our list of measurements $X=[X_1, \dots, X_n]$.
   Then,
   $$
   X_i = \mu + B + \epsilon_i
   $$
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import matplotlib.mlab as ML
   % data = ML.csv2rec('%s/apples_oranges.csv' % datadir)['apple_errors'] + 8 + 2
   % pylab.hist(data, bins=30, facecolor='blue', alpha=0.5, label='Biased')
   % pylab.hist(data-2, bins=30, facecolor='red', alpha=0.5, label='Unbiased')
   % pylab.legend()
   % pylab.gca().set_yticks([])
   % pylab.gca().set_xlabel('Weight of apple (ounces)')
   % 


   \begin{frame}
   \frametitle{Histogram of apples with bias 2}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/da7a155695.pdf}}    
   \end{center}

   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Bias}

   \begin{block}
   {Problems encountered with bias}
   \begin{itemize}
   \item Bias doesn't disappear with repeated measurements
   $$
   \text{average}(\text{list with bias}) = \text{average}(\text{unbiased list}) + \text{bias}
   $$
   \item In $\Sigma$ notation
   $$
   \bar{X} = \mu + B + \bar{\epsilon}
   $$
   \item Becomes very worrying when trying to compare
   two averages.
   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Measurement}

   \begin{block}
   {Example: Weighing an apple and an orange}
   \begin{itemize}
   \item Suppose we also have an orange that weights exactly 8 ounces.
   \item We weigh the apple and orange 100 different times each.
   \item The scale we use for the orange has same SD, but has a positive
   bias of 2 ounces.
   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import matplotlib.mlab as ML
   % data = ML.csv2rec('%s/apples_oranges.csv' % datadir)
   % apples = data['apple_errors'] + 8
   % oranges = data['orange_errors'] + 8 + 2
   % pylab.hist(apples, bins=30, facecolor='blue', alpha=0.5, label='Apples')
   % pylab.hist(oranges, bins=30, facecolor='red', alpha=0.5, label='Oranges')
   % pylab.legend()
   % # pylab.gca().set_yticks([])
   % pylab.gca().set_xlabel('Weight (ounces)')
   % 


   \begin{frame}
   \frametitle{Histogram of apples and oranges}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/788f0fb4ee.pdf}}    
   \end{center}

   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Bias}

   \begin{block}
   {Dealing with bias}
   \begin{itemize}
   \item What if we weighed the apple half the time on one scale
   and half on the other?

   \item And did the same with the oranges \dots

   \item Will the histogram still look like a normal curve?

   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import matplotlib.mlab as ML
   % data = ML.csv2rec('%s/apples_oranges.csv' % datadir)
   % apples = data['apple_errors'] + 8
   % oranges = data['orange_errors'] + 8
   % random = data['random']
   % data = apples + random
   % pylab.hist(data[random != 0], bins=30, facecolor='blue', alpha=0.5, label='Scale 2')
   % pylab.hist(data[random == 0], bins=30, facecolor='red', alpha=0.5, label='Scale 1')
   % pylab.legend()
   % pylab.gca().set_title('Mean(scale 1): %0.1f, SD(scale 1): %0.1f; Mean(scale 2)=%0.1f, SD(scale 2)=%0.1f' % ((data[random == 0]).mean(), (data[random == 0]).std(), (data[random != 0]).mean(), (data[random != 0]).std()), size='small')
   % pylab.gca().set_yticks([])
   % pylab.gca().set_xlabel('Weight (ounces)')
   % 


   \begin{frame}
   \frametitle{Histogram of apples on two scales}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/a3f2efff7b.pdf}}    
   \end{center}

   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import matplotlib.mlab as ML
   % data = ML.csv2rec('%s/apples_oranges.csv' % datadir)
   % apples = data['apple_errors'] + 8
   % oranges = data['orange_errors'] + 8
   % random = data['random']
   % data = apples + random
   % pylab.hist(data, bins=30, facecolor='blue', alpha=0.5, label='Combined')
   % pylab.gca().set_yticks([])
   % pylab.gca().set_xlabel('Weight (ounces)')
   % pylab.gca().set_title('Mean: %0.1f, SD: %0.1f' % (data.mean(), data.std()))
   % 


   \begin{frame}
   \frametitle{Histogram of apples combined}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/b24f0202da.pdf}}    
   \end{center}
   Close to a normal curve, but not quite
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import matplotlib.mlab as ML
   % data = ML.csv2rec('%s/apples_oranges.csv' % datadir)
   % apples = data['apple_errors'] + 8
   % oranges = data['orange_errors'] + 8
   % random = data['random']
   % data = apples + random
   % pylab.hist(apples + random, bins=30, facecolor='blue', alpha=0.5, label='Apples')
   % pylab.hist(oranges + 2 - random, bins=30, facecolor='red', alpha=0.5, label='Oranges')
   % pylab.legend()
   % pylab.gca().set_yticks([])
   % pylab.gca().set_xlabel('Weight (ounces)')
   % pylab.gca().set_title('Mean(apples): %0.1f, SD(apples): %0.1f; Mean(oranges)=%0.1f, SD(oranges)=%0.1f' % ((apples+random).mean(), (apples+random).std(), (oranges + 2 - random).mean(), (oranges + 2 - random).std()), size='small')
   % 


   \begin{frame}
   \frametitle{Histogram of apples \& oranges with randomization}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/a10922f30b.pdf}}    
   \end{center}

   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Bias}

   \begin{block}
   {Apples and oranges revisited}
   \begin{itemize}
   \item Randomizing the scale used didn't eliminate the bias
   of scale 2.
   \item But, it made the bias the same in Apples and Oranges.
   \item This allows us to compare Apples and Oranges fairly.
   \item The weights of the apples and oranges were {\em confounded} by the difference between the scales.
   \item The variable that says which scale was used to make each weight
   is a {\em confounding variable}.
   \item Randomization allowed us to eliminate this confounder.
   \end{itemize}
   \end{block}
   \end{frame}

   %CODE
       % from matplotlib import rc
   % import pylab, numpy as np, sys
   % np.random.seed(0);import random; random.seed(0)
   % import matplotlib.mlab as ML
   % data = ML.csv2rec('%s/apples_oranges.csv' % datadir)
   % apples = data['apple_errors']
   % oranges = data['orange_errors']
   % random = data['random']
   % data = apples + random
   % pylab.hist(apples + random, bins=30, facecolor='blue', alpha=0.5, label='Apples')
   % pylab.hist(oranges + 2 - random, bins=30, facecolor='red', alpha=0.5, label='Oranges')
   % pylab.legend()
   % pylab.gca().set_yticks([])
   % pylab.gca().set_xlabel('Chance error (ounces)')
   % pylab.gca().set_title('Mean(apples): %0.1f, SD(apples): %0.1f; Mean(oranges)=%0.1f, SD(oranges)=%0.1f' % ((apples+random).mean(), (apples+random).std(), (oranges + 2 - random).mean(), (oranges + 2 - random).std()), size='small')
   % 


   \begin{frame}
   \frametitle{Chance errors for apples \& oranges with randomization}
   \begin{center}
   \resizebox{!}{2.7in}{\includegraphics{./images/inline/e0753c2010.pdf}}    
   \end{center}

   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} \frametitle{Other ``measurements''}

   \begin{block}
   {Examples}
   \begin{itemize}
   \item Opinion polls. (Does our measurement model work here? What is bias?)

   \item Weighing 100 different apples on Scale 1 instead of 1 apple
   100 times. (Would you get the same SD? Would it be larger? Smaller?)

   \item The SAT test is a measurement of ``aptitude''. Each time
   you take a test, there is a new measurement.

   \item An MRI scan is a measurement (actually, several 100,000 measurements).

   \item Body weight is a measurement.
   \end{itemize}
   \end{block}
   \end{frame}

   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

   \begin{frame} 

   \end{frame}

   \end{document}
