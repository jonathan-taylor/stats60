{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:2bac36d3bc83f9ba9ee4a20bbf1760e04738bdaa65899516e96e1d5eaff5787d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 1,
     "source": [
      "Regression (Chapters 10-12)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%capture\n",
      "height = pearson_lee()\n",
      "height.strip = 65\n",
      "height.SDline()\n",
      "height.axes.scatter([65], [height.mean_strip], s=300, c='yellow', label='Average(strip)')\n",
      "height.axes.set_title('The average within the strip is %0.1f' % height.mean_strip, fontsize=15)\n",
      "matplotlib.rcParams['legend.scatterpoints'] = 1\n",
      "height.axes.legend(loc='lower right') \n",
      "daughter = height.D\n",
      "mother = height.M"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "height.figure"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 3,
     "source": [
      "Note that the average in the strip at 65in is below the SD line. Why?\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 3,
     "source": [
      "## Regression line\n",
      "\n",
      "- Instead of the SD line we choose a line that minimizes the \"vertical distances\" from each point to the line.\n",
      "- The quality of a line is measured by the r.m.s. of these distances, called ** residuals**.\n",
      "  \n",
      "- Each choice of slope / intercept yields a new set of residuals.\n",
      "- The regression line has the residuals with smallest r.m.s.\n",
      "- This is using the **method of least squares**\n",
      "   to choose the slope and intercept."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "intercept, slope = 20, 0.5\n",
      "residuals = daughter - (intercept + slope * mother)\n",
      "sqrt(sum(residuals**2) / len(mother))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "intercept, slope = 30, 0.5\n",
      "residuals = daughter - (intercept + slope * mother)\n",
      "sqrt(sum(residuals**2) / len(mother))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 5,
     "source": [
      "Intercept=4, Slope=0.3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%capture\n",
      "sample_fig = plt.figure()\n",
      "sample_ax = sample_fig.gca()\n",
      "D = csv2rec(resource_stream('stats_lectures', 'data/sample_regression.csv'))\n",
      "X = D['x']\n",
      "Y = D['y']\n",
      "sample_ax.scatter(X,Y, c='yellow', s=150)\n",
      "sample_ax.set_xlabel('X', fontsize=15)\n",
      "sample_ax.set_ylabel('Y', fontsize=15)\n",
      "del(D)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_fig"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "slope, intercept = 0.3, 4\n",
      "a = slope*X + intercept\n",
      "for i in range(X.shape[0]):\n",
      "    sample_ax.arrow(X[i], Y[i], 0, a[i] - Y[i], color='red')\n",
      "SSE = np.sum((a-Y)**2)\n",
      "sample_ax.plot([X.min(), X.max()],[0.3*X.min()+4,0.3*X.max()+4], 'r-', linewidth=3)\n",
      "sample_ax.set_title('Error(slope=%0.1f, intercept=%0.1f): %0.2f' % (slope, intercept, sqrt(SSE / X.shape[0])),\n",
      "             fontsize=15)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_fig"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 9,
     "source": [
      "\n",
      "Error is r.m.s. of ** lengths**\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sqrt(sum((Y - (0.3*X + 4))**2) / len(X))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 10,
     "source": [
      "SD line"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%capture\n",
      "SD_fig = plt.figure()\n",
      "sample_ax = SD_fig.gca()\n",
      "sample_ax.scatter(X,Y, c='yellow', s=150)\n",
      "sample_ax.set_xlabel('X', fontsize=15)\n",
      "sample_ax.set_ylabel('Y', fontsize=15)\n",
      "SDslope = Y.std() / X.std()\n",
      "SDintercept = Y.mean() - SDslope * X.mean()\n",
      "a = SDslope*X + SDintercept\n",
      "for i in range(X.shape[0]):\n",
      "    sample_ax.arrow(X[i], Y[i], 0, a[i] - Y[i], color='blue')\n",
      "SSE = np.sum((a-Y)**2)\n",
      "sample_ax.plot([X.min(), X.max()],[SDslope*X.min()+SDintercept,SDslope*X.max()+SDintercept], color='blue',\n",
      "               linestyle='-', linewidth=3)\n",
      "sample_ax.set_title('Error(SD line): %0.2f' % np.sqrt(SSE / X.shape[0]), fontsize=15)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SD_fig"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "prompt_number": 12,
     "source": [
      "## Regression line\n",
      "\n",
      "- The **regression line** is the line whose slope and intercept have the smallest\n",
      "`r.m.s.` for the vertical deviations from that line.\n",
      "\n",
      "- Define the **point of averages** of two lists $X$ and $Y$ as\n",
      "\n",
      "      point of averages(X, Y) = (average(X), average(Y))\n",
      "\n",
      "- The regression line passes through the point of averages and has slope:\n",
      "$$\\text{slope} = r(X,Y) \\times \\frac{SD(Y)}{SD(X)}.$$\n",
      "\n",
      "- The intercept of the regression line is\n",
      " \n",
      "      intercept = average(Y) - slope * average(X)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "point_of_averages = (mean(X), mean(Y))\n",
      "sample_ax.scatter(point_of_averages[0], point_of_averages[1], marker='+', \n",
      "                  color='red', s=500, linewidth=5, label='Point of averages')\n",
      "sample_ax.legend(loc='lower right')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SD_fig"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 14,
     "source": [
      "Fit for regression line"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%capture\n",
      "reg_fig = plt.figure()\n",
      "sample_ax = reg_fig.gca()\n",
      "sample_ax.scatter(X,Y, c='yellow', s=150)\n",
      "sample_ax.set_xlabel('X', fontsize=15)\n",
      "sample_ax.set_ylabel('Y', fontsize=15)\n",
      "\n",
      "reg_slope = np.corrcoef([X,Y])[0,1] * Y.std() / X.std()\n",
      "reg_intercept = Y.mean() - reg_slope * X.mean()\n",
      "a = reg_slope*X + reg_intercept\n",
      "for i in range(X.shape[0]):\n",
      "    sample_ax.arrow(X[i], Y[i], 0, a[i] - Y[i], color='red')\n",
      "\n",
      "SSE = np.sum((a-Y)**2)\n",
      "sample_ax.plot([X.min(), X.max()],[reg_slope*X.min()+reg_intercept,\n",
      "                                   reg_slope*X.max()+reg_intercept], color='red',\n",
      "               linestyle='-', linewidth=3)\n",
      "sample_ax.set_title('Error(regression line): %0.2f' % np.sqrt(SSE / X.shape[0]), fontsize=15)\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reg_fig"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 16,
     "source": [
      "The regression line has better `r.m.s.` for the vertical deviations!\n",
      "\n",
      "In this example, the difference is not huge. Let's look back at the \n",
      "mother / daughter heights."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%capture\n",
      "\n",
      "def error(a,b):\n",
      "    F = a*M+b\n",
      "    return np.sqrt(np.sum((D-F)**2))\n",
      "\n",
      "D, M = daughter, mother\n",
      "r = np.corrcoef([D,M])[0,1]\n",
      "slope_SD = D.std() / M.std()\n",
      "intercept_SD = D.mean() - slope_SD * M.mean()\n",
      "\n",
      "slope_r = r * D.std() / M.std()\n",
      "intercept_r = D.mean() - slope_r * M.mean()\n",
      "\n",
      "height.axes.set_title('Error(SD line)=%0.1f, Error(regression)=%0.1f' %\n",
      "            (error(slope_SD, intercept_SD),\n",
      "            error(slope_r, intercept_r)), fontsize=15)\n",
      "height.regline(draw=False)\n",
      "height.axes.legend(loc=('upper left'))\n",
      "del(D); del(M)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "height.figure"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 18,
     "source": [
      "Let's look at those strip averages we computed in the notes on correlation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mother_heights = range(56,69)\n",
      "averages = []\n",
      "for mother in mother_heights:\n",
      "    height.strip = mother\n",
      "    averages.append(height.mean_strip)\n",
      "height.axes.scatter(mother_heights, averages, s=300, c='yellow')"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "height.figure"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 20,
     "source": [
      "**The regression line almost sits on top of the strip averages!**\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 20,
     "source": [
      "## Working with regression problems\n",
      "\n",
      " The following quantities are enough to do all regression problems\n",
      "* $\\text{average}(X), \\text{SD}(X)$\n",
      "* $\\text{average}(X), \\text{SD}(Y)$\n",
      "* $r(X,Y)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 20,
     "source": [
      "### Blood alcohol example\n",
      "\n",
      "It is believed that the more alcohol there is in a person\u2019s blood stream, the slower is that person\u2019s reaction times. An experiment with 10 subjects yields\n",
      "- average amount of alcohol in blood $0.14\\%$ with SD $0.04\\%$;\n",
      "- average reaction time 0.42 seconds, SD 0.1 seconds;\n",
      "- correlation coefficient 0.8.\n",
      "\n",
      "**Predict the reaction time of a person with an amount of alcohol of 0.22%.**\n",
      "\n",
      "#### Answer\n",
      "\n",
      "- We first compute the slope, intercept \n",
      "    $$\\begin{aligned}\n",
      "     \\text{slope} &= \\frac{0.8 \\times 0.1}{0.04} = 2.0 \\frac{\\text{seconds}}{\\%}     \\\\\n",
      "     \\text{intercept} &= 0.42 - 2. \\times 0.14 = 0.14 \\, \\text{seconds}\n",
      "     \\end{aligned}$$ \n",
      "     \n",
      "     Plugging in an alcohol level of 0.22 yields a predicted time of\n",
      "     $$2 \\times 0.22 + 0.14 = 0.58 \\, \\text{seconds}.$$\n",
      "     \n",
      "- Another way to arrive at the same answer is to note that $(0.14,0.42)$\n",
      "is the point of averages which is on the regression line. For any other value of blood alcohol, $B$, the corresponding point $y$-value of reaction time on the regression line is \n",
      "$$\n",
      "0.42 + (B - 0.14) * 2.\n",
      "$$\n",
      "Substituting $B=0.22$ yields\n",
      "$$\n",
      "0.42 + (0.22-0.14)*2. = 0.42 + 0.16 = 0.58.\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 20,
     "source": [
      "### Blood alcohol example\n",
      "\n",
      "**Find the regression line for regressing reaction time on alcohol level.**\n",
      "\n",
      "\n",
      "#### Answer\n",
      "\n",
      "Having already computed the slope and intercept of this line, the regression line is described by the equation\n",
      "\n",
      "       reaction_time = 0.14 + 2 * alcohol level\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 20,
     "source": [
      "### Blood alcohol example\n",
      "\n",
      "**Predict the reaction time of a person whose alcohol level is at the 20th percentile. What percentile does that correspond to in reaction time?**\n",
      "\n",
      "#### Answer\n",
      "\n",
      "The 20th percentile of blood alcohol is (using normal approximation) $$\\begin{aligned}\n",
      "     0.14 + 0.04 \\times \\text{20th percentile of normal}\n",
      "     &  = 0.14 + 0.04 \\times (-0.84) \\\\\n",
      "     & = 0.11\n",
      "     \\end{aligned}$$ \n",
      "     \n",
      "So, we predict a reaction time of **$0.14 + 2 \\times 0.11 = 0.36$.**\n",
      "\n",
      "The second part of the question asks us to find roughly what percentile this corresponds to. We will use the normal approximation. \n",
      "\n",
      "Converting to standardize units, we see a reaction time of 0.36 is\n",
      "$$\n",
      "\\frac{0.36-0.42}{0.1} = -0.6.\n",
      "$$\n",
      "Table A-104 tells us this is roughly the 30th percentile."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 20,
     "source": [
      "#### Blood alcohol example\n",
      "\n",
      "**Predict the amount of alcohol a person has in her bloodstream if the reaction time is 0.37 seconds.**\n",
      "\n",
      "#### Answer\n",
      "\n",
      "We invert the relationship in the regression line:\n",
      "\n",
      "       blood_alcohol = (reaction_time - 0.14) / 2\n",
      "       \n",
      "Substituting `reaction_time=0.37` yields **`blood_alcohol = (.37-.14)/2 = .125`**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 20,
     "source": [
      "## Regression fallacy\n",
      "\n",
      "* Note that someone in the 20th percentile of `blood alcohol` had predicted 30th percentile in `reaction time`.\n",
      "\n",
      "* This is a general phenomenon, Galton referred to it as \"regression to mediocrity.\"\n",
      "\n",
      "### Test-retest version of regression fallacy (from book)\n",
      "\n",
      "In a test-retest situation, usually the bottom group on the \n",
      "first test will show some improvement, and the top group will fall back."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 20,
     "source": [
      "\n",
      "There are two regression lines:\n",
      "\n",
      "- One line has `mother` as independent variable, `daughter` as dependent variable.\n",
      "\n",
      "- The other line has `daughter` as independent variable, `mother` as dependent variable."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%capture\n",
      "height = pearson_lee()\n",
      "height.SDline()\n",
      "height.regline(draw=False, label='D on M')\n",
      "height.invregline(draw=False, label='M on D')\n",
      "height.axes.legend(loc='lower right')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "height.figure"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 22,
     "source": [
      "## Prediction and regression\n",
      "\n",
      "- While there are two regression lines, the right way to remember which to use is **what do you want to predict?**\n",
      "- The variable you want to predict goes on the vertical axis ($Y$-axis).\n",
      "- The variable you want to base your prediction on goes on the vertical axis ($X$-axis).\n",
      "- In many situations, it will be more natural to predict one variable instead of another."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "prompt_number": 22,
     "source": [
      "\n",
      "Accuracy of prediction\n",
      "\n",
      "* In discussing experiments, we discussed the average of a set of measurements.\n",
      "* These can be used to predict a new measurement: our best guess is just the average of the previous meausrements."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 22,
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "prompt_number": 22,
     "source": [
      "\n",
      "SD as a measure of accuracy\n",
      "\n",
      "* The SD of the set of measurements gives us some idea of how accurate our prediction is $\\text{SD(list) = r.m.s.(deviations from average)}$\n",
      "* If our prediction is the average, then $\\text{SD(list) = r.m.s.(deviations from predictions)}$\n",
      "* With regression, we have a new way to predict: using the regression line."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 22,
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "prompt_number": 22,
     "source": [
      "\n",
      "Accuracy of prediction in regression\n",
      "\n",
      "* In regression, we are using more information: the fact that tall mothers tend to give birth to taller daughters (but not quite as tall).\n",
      "* This should improve the accuracy of our prediction of the daughter\u2019s height (which uses the mother\u2019s height)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 22,
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "prompt_number": 22,
     "source": [
      "\n",
      " of regression\n",
      "\n",
      "* Our regression line was chosen to minimize the r.m.s. of the residuals of all ines $$\n",
      "* () &=\n",
      "  &=\n",
      "  \n",
      "* $$\n",
      "* This r.m.s. is always less than the SD of the dependent variable ($Y$) alone $$ () = (Y) $$\n",
      "* In mother/daughter example, this factor is 87%."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 22,
     "source": [
      "SD is based on residuals"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "X = seq(0,20, length=21)\n",
      "Y = 0.5*X+1 + rnorm(21)\n",
      "\n",
      "Y.lm = lm(Y~X)\n",
      "\n",
      "p = predict(Y.lm)\n",
      "m = mean(Y)\n",
      "\n",
      "# SST: deviations of Y's around\n",
      "# the horizontal line for the mean\n",
      "\n",
      "plot(X, Y, pch=23, bg='red')\n",
      "abline(h=m, col='yellow', lwd=2)\n",
      "for (i in 1:21) {\n",
      "  points(X[i], m, pch=23, bg='yellow')\n",
      "  lines(c(X[i], X[i]), c(Y[i], m))\n",
      "}\n",
      "\n",
      "# show the regression line as well\n",
      "\n",
      "abline(Y.lm, col='green', lwd=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 23,
     "source": [
      "So is r.m.s.(regression)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "# SSE: deviations of Y's around\n",
      "# the regression line\n",
      "\n",
      "plot(X, Y, pch=23, bg='red')\n",
      "abline(Y.lm, col='green', lwd=2)\n",
      "for (i in 1:21) {\n",
      "  points(X[i], p[i], pch=23, bg='green')\n",
      "  lines(c(X[i], X[i]), c(Y[i], p[i]))\n",
      "}\n",
      "\n",
      "m = mean(Y)\n",
      "abline(h=m, col='yellow', lwd=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 24,
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "prompt_number": 24,
     "source": [
      "\n",
      " of regression\n",
      "\n",
      "* If the data cloud is football shaped, then the r.m.s. gives an estimate of the spread in each vertical strip of the regression line.\n",
      "* This is * homoscedastic*\n",
      "   scatter.\n",
      "* If the data cloud has a different shape, this scatter is called * heteroscedastic*\n",
      "   and the regression r.m.s. is not useful within a vertical strip"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 24,
     "source": [
      "Homoscedastic scatter"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 300\n",
      "X = np.random.standard_normal(n)\n",
      "X.sort()\n",
      "w = 3\n",
      "Y = 4.5 * X + 1 + np.random.standard_normal(n) * w\n",
      "\n",
      "xf, yf = pylab.poly_between([-1.25,-0.75], [-20,-20], [20, 20])\n",
      "pylab.fill(xf, yf, facecolor='blue', alpha=0.4, hatch='/', label='_nolegend_')\n",
      "\n",
      "xf, yf = pylab.poly_between([0.75,1.25], [-20,-20], [20, 20])\n",
      "pylab.fill(xf, yf, facecolor='blue', alpha=0.4, hatch='/', label='_nolegend_')\n",
      "\n",
      "pylab.gca().set_yticks([])\n",
      "pylab.gca().set_xticks([])\n",
      "pylab.scatter(X, Y, c='red')\n",
      "pylab.gca().set_ylim([-10,15])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 25,
     "source": [
      "Heteroscedastic scatter"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 300\n",
      "X = np.random.standard_normal(n)\n",
      "X.sort()\n",
      "w = np.linspace(1,6,n)\n",
      "Y = 0.5 * X + 1 + np.random.standard_normal(n) * w\n",
      "\n",
      "xf, yf = pylab.poly_between([-1.25,-0.75], [-20,-20], [20, 20])\n",
      "pylab.fill(xf, yf, facecolor='blue', alpha=0.4, hatch='/', label='_nolegend_')\n",
      "\n",
      "xf, yf = pylab.poly_between([0.75,1.25], [-20,-20], [20, 20])\n",
      "pylab.fill(xf, yf, facecolor='blue', alpha=0.4, hatch='/', label='_nolegend_')\n",
      "\n",
      "pylab.gca().set_yticks([])\n",
      "pylab.gca().set_xticks([])\n",
      "pylab.scatter(X, Y, c='red')\n",
      "pylab.gca().set_ylim([-10,15])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 26,
     "source": [
      "Income vs. Education"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "D = csv2rec('%s/wage.csv' % datadir)\n",
      "X = D['education']\n",
      "Y = D['logwage']\n",
      "Z = np.exp(Y)\n",
      "\n",
      "\n",
      "pylab.scatter(X, Z, c='red')\n",
      "a = pylab.gca()\n",
      "a.set_ylabel('Income (1000$)')\n",
      "a.set_xlabel('Education (years)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 27,
     "source": [
      "log(Income) vs. Education"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = D['education']\n",
      "Y = D['logwage']\n",
      "Z = np.exp(Y)\n",
      "\n",
      "\n",
      "pylab.scatter(X, Y, c='red')\n",
      "a = pylab.gca()\n",
      "a.set_ylabel('log(Income (1000$))')\n",
      "a.set_xlabel('Education (years)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "prompt_number": 28,
     "source": [
      "\n",
      "Logarithms may improve heteroscedastic scatter"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 28,
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "prompt_number": 28,
     "source": [
      "\n",
      "Example: using regression r.m.s. in vertical strips\n",
      "\n",
      "* Given the following $\\begin{aligned}\n",
      "         \\text{average(mother)} &= 62.4\\\\\n",
      "         \\text{SD(mother)} &= 2.3 \\\\\n",
      "         \\text{average(daughter)} &= 63.8 \\\\\n",
      "         \\text{SD(daughter)} &= 2.6 \\\\\n",
      "         \\text{r(mother, daughter)} &= 0.49\n",
      "       \\end{aligned}$ Of mothers of height 66in, what percentage of their daughters will have height above 67in?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 28,
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "prompt_number": 28,
     "source": [
      "\n",
      "Answer\n",
      "\n",
      "* Slope of regression line is $\\text{slope} = 0.49 \\times \\frac{2.6}{2.3} = 0.54$\n",
      "* The average height of daughters of mothers of height 66in is $63.8 + 0.54 \\times (66 - 62.4) = 65.7$\n",
      "* The SD is taken to be r.m.s. of regression $0.87 \\times 2.6 = 2.3.$\n",
      "* 67 in corresponds to $(67-65.7)/2.3=0.6$ standardized units.\n",
      "* From A-104, the percentage is roughly 27%."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 28,
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "D = csv2rec('%s/quadratic_example.csv' % datadir)\n",
      "X = D['x']\n",
      "Y = D['y']\n",
      "pylab.scatter(X,Y, c='r', s=40)\n",
      "m = Y.std() * np.corrcoef([X,Y])[0,1] / X.std()\n",
      "b = Y.mean() - X.mean() * m\n",
      "\n",
      "r = ((X*Y).mean() - X.mean() * Y.mean()) / (X.std() * Y.std())\n",
      "pylab.plot([X.mean()-3.5*X.std(),X.mean()+3.5*X.std()],\n",
      "           [Y.mean()-r*3.5*Y.std(),Y.mean()+r*3.5*Y.std()],\n",
      "           '-', linewidth=3, label='M on D', color='black')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "prompt_number": 29,
     "source": [
      "\n",
      "Regression doesn\u2019t work well for nonlinear patterns"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 29,
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "D = csv2rec('%s/quadratic_example.csv' % datadir)\n",
      "X = D['x']\n",
      "Y = D['y']\n",
      "m = Y.std() * np.corrcoef([X,Y])[0,1] / X.std()\n",
      "b = Y.mean() - X.mean() * m\n",
      "\n",
      "p = m * X + b\n",
      "resid = Y - p\n",
      "pylab.scatter(X, resid, c='r', s=40)\n",
      "pylab.gca().set_ylabel('Residuals')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "prompt_number": 30,
     "source": [
      "\n",
      "Plotting the residuals can identify nonlinear patterns"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 30,
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "D = csv2rec('%s/heteroscedastic_example.csv' % datadir)\n",
      "X = D['x']\n",
      "Y = D['y']\n",
      "\n",
      "pylab.scatter(X, Y, s=40, c='red')\n",
      "pylab.gca().set_ylim([-10,15])\n",
      "m = Y.std() * np.corrcoef([X,Y])[0,1] / X.std()\n",
      "b = Y.mean() - X.mean() * m\n",
      "\n",
      "r = ((X*Y).mean() - X.mean() * Y.mean()) / (X.std() * Y.std())\n",
      "pylab.plot([X.mean()-3.5*X.std(),X.mean()+3.5*X.std()],\n",
      "           [Y.mean()-r*3.5*Y.std(),Y.mean()+r*3.5*Y.std()],\n",
      "           '-', linewidth=3, label='M on D', color='black')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 31,
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "D = csv2rec('%s/heteroscedastic_example.csv' % datadir)\n",
      "X = D['x']\n",
      "Y = D['y']\n",
      "\n",
      "m = Y.std() * np.corrcoef([X,Y])[0,1] / X.std()\n",
      "b = Y.mean() - X.mean() * m\n",
      "\n",
      "p = m * X + b\n",
      "resid = Y - p\n",
      "pylab.scatter(X, resid, c='r', s=40)\n",
      "pylab.gca().set_ylabel('Residuals')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "prompt_number": 32,
     "source": [
      "\n",
      "Can also help identify heteroscedasticity"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}