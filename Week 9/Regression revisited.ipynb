{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:ad1dd8589f08f3db620ce04af38eb9484a194f6a3446b3f5ea04ea3fe16a6e80"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 1,
     "source": [
      "Simple linear regression "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 1,
     "source": [
      "The first type of model, which we will spend a lot of time on, is the *simple linear regresssion model*. One simple way to think of it\n",
      "is via scatter plots. Below are [heights](http://www.stat.cmu.edu/~roeder/stat707/=data/=data/data/Rlibraries/alr3/html/heights.html) of mothers and daughters collected \n",
      "by Karl Pearson in the late 19th century. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R -o M,D\n",
      "library(alr3)\n",
      "data(heights)\n",
      "M = heights$Mheight\n",
      "D = heights$Dheight"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "heights_fig = plt.figure(figsize=(10,6))\n",
      "axes = heights_fig.gca()\n",
      "axes.scatter(M, D, c='red')\n",
      "axes.set_xlabel(\"Mother's height (inches)\", size=20)\n",
      "axes.set_ylabel(\"Daughter's height (inches)\", size=20)\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 3,
     "source": [
      "The regression model puts a line through this scatter plot in an *optimal* fashion.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R -o slope,intercept\n",
      "parameters = lm(D~M)$coef\n",
      "print(parameters)\n",
      "intercept = parameters[1]\n",
      "slope = parameters[2]"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "axes.plot([M.min(), M.max()], [intercept + slope * M.min(), intercept + slope * M.max()],\n",
      "          linewidth=3)\n",
      "heights_fig\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 5,
     "source": [
      "Simple linear regression model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 5,
     "source": [
      " *  *Simple linear* regression is the case when there is only one predictor:\n",
      "   $$\n",
      "   f({\\tt Mother}) = \\beta_0 + \\beta_1  \\cdot {\\tt Mother}.$$\n",
      "\n",
      "* Let $Y_i$ be the height of the $i$-th daughter in the sample, $X_i$ be the height of the $i$-th mother.\n",
      "\n",
      "* Model:\n",
      "   $$\n",
      "   Y_i = \\underbrace{\\beta_0 + \\beta_1 X_i}_{\\text{regression equation}} + \\underbrace{\\varepsilon_i}_{\\text{error}}$$\n",
      "   where $\\varepsilon_i \\sim N(0, \\sigma^2)$ are independent.\n",
      "\n",
      "* This specifies a *distribution* for the $Y$'s given the $X$'s, i.e.\n",
      "   it is a *statistical model*.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 5,
     "source": [
      "Example: wages vs. experience"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 5,
     "source": [
      "\n",
      "In this example, we'll look at the output of *lm* for the wage\n",
      "data and verify that some of the equations we present for the \n",
      "least squares solutions agree with the output.\n",
      "The data was compiled from a study in econometrics [Learning about Heterogeneity in Returns to Schooling]( http://www.econ.queensu.ca/jae/2004-v19.7/koop-tobias/readme.kt.txt).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "url = 'http://stats191.stanford.edu/data/wage.csv'\n",
      "wages = read.table(url, sep=',', header=T)\n",
      "print(head(wages))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 6,
     "source": [
      "Let's fit the linear regression model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "wages.lm = lm(logwage ~ education, data=wages)\n",
      "print(wages.lm)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 7,
     "source": [
      "As in the mother-daughter data, we might want to plot the data and add the regression line."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R -h 800 -w 800\n",
      "plot(education, logwage, pch=23, bg='red', cex=2)\n",
      "abline(wages.lm, lwd=4, col='black')"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 8,
     "source": [
      "Least squares estimators"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 8,
     "source": [
      "There are explicit formulae for the least squares estimators, i.e. the minimizers of the error sum of squares.\n",
      "\n",
      "For the slope, $\\hat{\\beta}_1$, it can be shown that \n",
      "$$\n",
      "   \\widehat{\\beta}_1 = \\frac{\\sum_{i=1}^n(X_i - \\overline{X})(Y_i - \\overline{Y}\n",
      ")}{\\sum_{i=1}^n (X_i-\\overline{X})^2} = \\frac{\\widehat{Cov}(X,Y)}{\\widehat{Var}(\n",
      "X)}.$$\n",
      "\n",
      "Knowing the slope estimate, the intercept estimate can be found easily:\n",
      "$$ \\widehat{\\beta}_0 = \\overline{Y} - \\widehat{\\beta}_1 \\cdot \\overline{\n",
      "X}.$$\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 8,
     "source": [
      "Estimate of $\\sigma^2$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 8,
     "source": [
      "There is one final quantity needed to estimate all of our parameters in our (statistical) model for the scatterplot. This is $\\sigma^2$,\n",
      "the variance of the random variation within each slice (the regression model assumes this variance is constant within each slice...).\n",
      "\n",
      "The estimate most commonly used is\n",
      "$$\n",
      "\\hat{\\sigma}^2 = \\frac{1}{n-2} \\sum_{i=1}^n (Y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 X_i)^2 = \\frac{SSE}{n-2} = MSE\n",
      "$$\n",
      "\n",
      "Above, note the practice of replacing the quantity $SSE(\\hat{\\beta}_0,\\hat{\\beta}_1)$, i.e. the minimum of this function, with just $SSE$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 8,
     "source": [
      "The term *MSE* above refers to mean squared error: a sum of squares divided by what we call its *degrees of freedom*. The degrees of freedom\n",
      "of *SSE*, the *error sum of squares* is therefore $n-2$. Remember this $n-2$ corresponded to $\\perp$ in the picture above...\n",
      "\n",
      "Using some statistical calculations that we will not dwell on, if our simple linear regression model is correct, then we can see that\n",
      "$$\n",
      "\\frac{\\hat{\\sigma}^2}{\\sigma^2} \\sim \\frac{\\chi^2_{n-2}}{n-2}\n",
      "$$\n",
      "where the right hand side denotes a *chi-squared* distribution with $n-2$ degrees of freedom."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 8,
     "source": [
      "Wages example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "sigma.hat = sqrt(sum(resid(wages.lm)^2) / wages.lm$df.resid)\n",
      "sigma.hat"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 9,
     "source": [
      "The summary from *R* also contains this estimate of $\\sigma$:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "summary(wages.lm)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 10,
     "source": [
      "Inference for the simple linear regression model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 10,
     "source": [
      "* Recall our model $$\n",
      "   Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i,$$\n",
      "   errors $\\varepsilon_i$ are independent $N(0, \\sigma^2)$.\n",
      "   \n",
      "* In our heights example, we might want to now if there\n",
      "   really is a linear association between ${\\tt Daughter}=Y$\n",
      "   and ${\\tt Mother}=X$. This can be answered with a *hypothesis test* of the null hypothesis $H_0:\\beta_1=0$.\n",
      "   This assumes the model above is correct, but that $\\beta_1=0$.\n",
      "   \n",
      "* Alternatively, we might want to have a range of values that we can be fairly certain $\\beta_1$ lies within.\n",
      "This is a *confidence interval* for $\\beta_1$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 10,
     "source": [
      "Setup for inference"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 10,
     "source": [
      "* It turns out that\n",
      "$$\n",
      "   \\widehat{\\beta}_1 \\sim N\\left(\\beta_1, \\frac{\\sigma^2}{\\sum_{i=1}^n(X_i-\\overline{X})^2}\\right).$$\n",
      "\n",
      "* Therefore, $$\\frac{\\widehat{\\beta}_1 - \\beta_1}{\\sigma \\sqrt{\\frac{1}{\\sum_{i=1}^n(X_i-\\overline{X})^2}}} \\sim N(\\\n",
      "0,1).$$\n",
      "\n",
      "* The other quantity we need is the *standard error* or SE of $\\hat{\\beta}_1$. This is\n",
      "obtained from estimating the variance of $\\widehat{\\beta}_1$, which, in this case means simply\n",
      "plugging in our estimate of $\\sigma$, yielding\n",
      "$$\n",
      "   SE(\\widehat{\\beta}_1) = \\widehat{\\sigma} \\sqrt{\\frac{1}{\\sum_{i=1}^n(X_i-\\overline{X})^2}} \\qquad \n",
      "   \\text{independent of $\\widehat{\\beta}_1$}$$\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 10,
     "source": [
      "Testing $H_0:\\beta_1=\\beta_1^0$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 10,
     "source": [
      "* Suppose we want to test that $\\beta_1$ is some pre-specified\n",
      "   value, $\\beta_1^0$ (this is often 0: i.e. is there a linear association)\n",
      "\n",
      "* Under $H_0:\\beta_1=\\beta_1^0$\n",
      "   $$\\frac{\\widehat{\\beta}_1 - \\beta^0_1}{\\widehat{\\sigma} \\sqrt{\\frac{1}{\\sum_{i=1}^n(X_i-\\overline{X})^2}}}\n",
      "   = \\frac{\\widehat{\\beta}_1 - \\beta^0_1}{ \\frac{\\widehat{\\sigma}}{\\sigma}\\cdot \\sigma \\sqrt{\\frac{1}{\n",
      "\\sum_{i=1}^n(X_i-\\overline{X})^2}}} \\sim t_{n-2}.$$\n",
      "\n",
      "\n",
      "* Reject $H_0:\\beta_1=\\beta_1^0$ if $|T| > t_{n-2, 1-\\alpha/2}$.\n",
      "   "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 10,
     "source": [
      "Wage example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 10,
     "source": [
      "Let's perform this test for the wage data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "beta.1.hat = wages.lm$coef[\"education\"]\n",
      "SE.beta.1.hat = (sigma.hat * sqrt(1 / sum((education - mean(education))^2)))\n",
      "Tstat = beta.1.hat / SE.beta.1.hat\n",
      "data.frame(beta.1.hat, SE.beta.1.hat, Tstat)\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 11,
     "source": [
      "Let's look at the output of the `lm` function again."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "summary(wages.lm)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 12,
     "source": [
      "We see that *R* performs this test in the second row of the `Coefficients` table. It is clear that\n",
      "wages are correlated with education."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 12,
     "source": [
      "Confidence interval based on Student's $t$ distribution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 12,
     "source": [
      "*   Suppose we have a parameter estimate $\\widehat{\\theta} \\sim N(\\theta, {\\sigma}_{\\theta}^2)$, and standard error $SE(\\widehat{\\theta})$ such that\n",
      "   $$\n",
      "   \\frac{\\widehat{\\theta}-\\theta}{SE(\\widehat{\\theta})} \\sim t_{\\nu}.$$\n",
      "\n",
      "* We can find a $(1-\\alpha) \\cdot 100 \\%$ confidence interval by:\n",
      "   $$\n",
      "   \\widehat{\\theta} \\pm SE(\\widehat{\\theta}) \\cdot t_{\\nu, 1-\\alpha/2}.$$\n",
      "   \n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 12,
     "source": [
      "Confidence interval for regression parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 12,
     "source": [
      "* Applying the above to the parameter $\\beta_1$ yields a confidence interval of the form\n",
      "$$\n",
      "   \\hat{\\beta}_1 \\pm SE(\\hat{\\beta}_1) \\cdot t_{n-2, 1-\\alpha/2}.$$\n",
      "   \n",
      "* We will need to compute $SE(\\hat{\\beta}_1)$. This can be computed using this formula\n",
      "   $$\n",
      "   SE(a_0\\hat{\\beta}_0 + a_1\\hat{\\beta}_1) = \\hat{\\sigma} \\sqrt{\\frac{a_0^2}{n} + \\frac{(a_0\\overline{X} - a_1)^2}{\\sum_{i=1}^n \\left(X_i-\\overline{X}\\right)^2}}.$$\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "prompt_number": 12,
     "source": [
      "We also need to find the quantity $t_{n-2,1-\\alpha/2}$. This is defined by\n",
      "$$\n",
      "\\mathbb{P}(T_{n-2} \\geq t_{n-2,1-\\alpha/2}) = \\alpha/2.\n",
      "$$\n",
      "In *R*, this is computed by the function `qt`.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "alpha = 0.05\n",
      "n = length(wages$education)\n",
      "qt(1-0.5*alpha,n-2)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "prompt_number": 13,
     "source": [
      "Not surprisingly, this is close to that of the normal distribution, which is a Student's $t$ with $\\infty$ for degrees of freedom."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "qnorm(1-0.5*alpha)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "L = beta.1.hat - qt(0.95, wages.lm$df.resid) * SE.beta.1.hat\n",
      "U = beta.1.hat + qt(0.95, wages.lm$df.resid) * SE.beta.1.hat\n",
      "data.frame(L, U)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "confint(wages.lm)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}